<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Game &amp; Code &amp; Art</title>
  <icon>https://www.gravatar.com/avatar/330f5084aa812faddf7523831352b490</icon>
  <subtitle>Holmodi的博客</subtitle>
  <link href="http://holmodi.fun/atom.xml" rel="self"/>
  
  <link href="http://holmodi.fun/"/>
  <updated>2023-09-04T07:15:00.355Z</updated>
  <id>http://holmodi.fun/</id>
  
  <author>
    <name>xiaodi xu</name>
    <email>294242549@qq.comh</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LLM辅助Agent决策论文阅读</title>
    <link href="http://holmodi.fun/posts/a7e72cd5.html"/>
    <id>http://holmodi.fun/posts/a7e72cd5.html</id>
    <published>2023-09-02T13:43:35.000Z</published>
    <updated>2023-09-04T07:15:00.355Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LLM辅助RL-Agent决策"><a href="#LLM辅助RL-Agent决策" class="headerlink" title="LLM辅助RL Agent决策"></a>LLM辅助RL Agent决策</h1><p>在多智能体强化学习中，由于同时涉及时间和结构尺度，适当分配奖励十分困难，尤其是在稀疏奖励的情况下。自动生成子目标的方法近年来在多智能体强化学习中得到了广泛应用，但是从稀疏奖励中学习复杂任务规划的端到端学习需要大量的训练样本，并且现有的方法往往会生成大量与实际任务奖励关联性有限的虚假子目标，降低了算法的样本效率。为了解决这个问题，现有的自动生成子目标的方法通常采用两阶段的端到端学习过程，首先生成每个智能体的子目标，然后学习使智能体实现这些子目标的策略。然而，这些方法往往需要大量的训练样本，并且由于多样性促进的表示学习方法可能会导致子目标的“过度表示”，生成大量与任务奖励关联性有限的冗余子目标，降低了算法的样本效率。 </p><h1 id="Semantically-Aligned-Task-Decomposition-in-MARL"><a href="#Semantically-Aligned-Task-Decomposition-in-MARL" class="headerlink" title="Semantically Aligned Task Decomposition in MARL"></a>Semantically Aligned Task Decomposition in MARL</h1><h2 id="Basic-Information"><a href="#Basic-Information" class="headerlink" title="Basic Information:"></a>Basic Information:</h2><ul><li>Title: Semantically Aligned Task Decomposition in MARL (多智能体强化学习中的语义对齐任务分解)</li><li>Keywords: Multi-Agent Reinforcement Learning, Task Decomposition, Sparse Reward, Automatic Subgoal Generation, Language-Grounded RL</li><li>URLs: <a href="https://arxiv.org/abs/2305.10865v1">Paper</a>, [GitHub: None]</li></ul><h2 id="论文简要"><a href="#论文简要" class="headerlink" title="论文简要 :"></a>论文简要 :</h2><p>本研究的研究思路是通过在多智能体强化学习中实现语义对齐的任务分解，帮助多智能体强化学习中有效地分配任务和子目标。论文提出了一种语义对齐的任务分解方法，确定需要完成的目标，然后基于各个智能体的能力和状态将目标分解为多个子目标。</p><p>本研究还设计了一种自我反思的决策检查方法，用于判断任务分解和子目标分配过程中是否出现错误。如果发现错误，决策检查者将接管错误的角色，并重新生成和分解目标，或重新分配子目标。</p><p>通过实现语义对齐的任务分解和有效的子目标分配，本研究解决了多智能体强化学习中任务分配和协作效率的问题。这种方法可以提高多智能体系统在协作任务中的性能，并实现更高效的任务完成。鉴于现有方法的局限性，本文受到解缠表示学习的启发，提出了一种新颖的“解缠”决策方法，即在多智能体强化学习中的语义对齐任务分解（SAMA）。SAMA利用预训练语言模型GPT作为先验知识和常识的来源，通过链式思维提示语言模型生成潜在目标，并提供适当的目标分解和子目标分配，以及基于自我反思的重新规划。此外，SAMA还结合了语言引导强化学习，训练每个智能体的子目标条件策略。通过在两个具有稀疏奖励的挑战性任务上的实验证明，SAMA相比于现有的自动生成子目标方法具有显著的样本效率优势。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法:"></a>方法:</h2><ul><li>本文讨论了合作多智能体强化学习（MARL）中稀疏奖励下的信用分配挑战。强调了在时间和结构尺度上分配信用的困难性。值分解框架通常用于解决结构性信用分配问题。在稀疏环境中学习沿轨迹分配信用的主要挑战是每个智能体通过随机探索获得有益轨迹的困难性。基于子目标的方法已经成为一种可行的替代方案，将任务分解为一系列目标和子目标。然而，现有的自动生成子目标（ASG）方法存在子目标过度表示的问题，导致样本效率降低。提出的方法，MARL中的语义对齐任务分解（SAMA），利用预训练的语言模型（PLMs）生成语义对齐和不重叠的子目标，解决了现有ASG方法的局限性。</li><li>提出的算法框架SAMA通过促使PLMs实现解耦、常识驱动的自动生成子目标，以解决MARL中的信用分配问题。它采用了一种语言基础机制，使每个智能体能够学习一个以自然语言子目标为条件的强化学习策略，以实现高效的MARL和PLM协作。SAMA在样本效率方面相比最先进的基于子目标的MARL方法具有明显的优势，这一点在Overcooked和MiniRTS的性能上得到了证明。当出现错误时，使用自反思机制来促使PLM重新规划任务。</li></ul><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><h2 id="OverCook多agent合作"><a href="#OverCook多agent合作" class="headerlink" title="OverCook多agent合作"></a>OverCook多agent合作</h2><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022143040.png"></p><h2 id="RTS游戏指挥"><a href="#RTS游戏指挥" class="headerlink" title="RTS游戏指挥"></a>RTS游戏指挥</h2><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022143076.png"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022146077.png"></p><h2 id="结果"><a href="#结果" class="headerlink" title="结果:"></a>结果:</h2><ul><li><p>文章中介绍了一种名为SAMA（Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning）的方法，并对其进行了实验评估。下面是每个步骤的研究结果和对实验假设的论证：</p><ol><li><p>实验假设：SAMA方法可以解决多智能体强化学习中的“样本稀缺”和“目标过度表示”挑战。</p></li><li><p>目标生成、分解和分配：通过使用预训练的语言模型（PLM），SAMA方法能够生成与自然语言任务手册语义对齐的目标，并将目标分解为子目标，并将子目标分配给每个智能体。实验结果表明，SAMA方法能够生成合适的目标，并将其分解和分配给智能体。</p></li><li><p>自我反思机制：SAMA方法引入了自我反思机制，用于改进语义对齐目标的生成、分解和分配过程。实验结果表明，自我反思机制能够显著提高SAMA方法的性能。</p></li><li><p>语言引导的强化学习：SAMA方法使用语言引导的强化学习来训练每个智能体的子目标条件策略。实验结果表明，语言引导的强化学习能够使智能体的策略与语义对齐的目标紧密匹配，并促进智能体之间的合作。</p></li></ol></li></ul><p>总体而言，实验结果支持了SAMA方法的有效性，并论证了实验假设。该方法能够解决多智能体强化学习中的挑战，并在长期、稀疏奖励和高度协作的任务中取得良好的性能。</p><p>- </p><ol><li><p>研究结论：本文的研究结论是通过语义对齐的任务分解方法在多智能体强化学习中实现了有效的目标分解和分配。该方法能够根据当前情况选择最合适的子目标，并使智能体能够独立地完成这些子目标，从而提高了多智能体系统的性能。</p></li><li><p>研究的创新性：本研究的创新性主要体现在以下几个方面：</p></li></ol><ul><li>引入了语义对齐的任务分解方法，通过对当前情况进行分析和推理，选择最合适的子目标，从而提高了任务分解的准确性和效率。</li><li>提出了一种有效的子目标分配策略，使得智能体能够独立地完成各自的子目标，从而提高了系统的并行性和整体性能。</li><li>在多智能体强化学习领域中，将语义对齐的任务分解方法应用于实际问题，并取得了良好的效果。</li></ul><ol start="3"><li>研究的不足之处：本研究还存在一些不足之处：</li></ol><ul><li>在实验中，只针对特定的游戏环境进行了验证，对于其他类型的任务和环境的适应性还需要进一步研究。</li><li>在目标分解和分配过程中，可能存在一定的误差和不确定性，需要进一步改进算法和方法，提高准确性和稳定性。</li><li>对于模型中可能存在的社会偏见和刻板印象的处理还需要更深入的研究和探讨。</li></ul><ol start="4"><li>研究展望：基于本研究的结果，可以进一步开展以下研究方向：</li></ol><ul><li>探索更多复杂任务和环境下的语义对齐的任务分解方法，提高系统的适应性和泛化能力。</li><li>进一步研究目标分解和分配的算法和策略，提高准确性和效率，并解决误差和不确定性的问题。</li><li>深入研究和解决模型中可能存在的社会偏见和刻板印象的问题，确保系统的公平性和中立性。</li><li>将语义对齐的任务分解方法应用于更广泛的领域，如自动驾驶、多智能体路径规划、云计算等，探索其在实际应用中的效果和潜在价值。</li></ul><ol start="5"><li>研究意义：</li></ol><ul><li>在理论上，本研究提出了一种新的任务分解方法，为多智能体强化学习领域的研究提供了新的思路和方法。</li><li>在实践上，本研究的方法可以应用于实际问题中，提高多智能体系统的性能和效率，具有一定的应用价值。</li></ul><h2 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h2><ul><li>提示词：</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022147889.png"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022147862.png"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309022147265.png"></p><h1 id="Basic-Information-1"><a href="#Basic-Information-1" class="headerlink" title="Basic Information:"></a>Basic Information:</h1><ul><li>Title: Hierarchical Decision Making by Generating and Following Natural Language Instructions (通过生成和遵循自然语言指令进行分层决策)</li><li>Authors: Hengyuan Hu, Denis Yarats, Qucheng Gong, Yuandong Tian, Mike Lewis</li><li>Affiliation: First author’s affiliation: Facebook AI Research (第一作者所属机构：Facebook AI Research)</li><li>Keywords: hierarchical decision making, natural language instructions, real-time strategy game, planning and execution, compositional structure (分层决策，自然语言指令，实时策略游戏，规划和执行，组合结构)</li><li>URLs: <a href="https://arxiv.org/abs/1906.00744v5">Paper</a>, <a href="https://github.com/facebookresearch/minirts">GitHub Code</a></li></ul><h1 id="论文简要-1"><a href="#论文简要-1" class="headerlink" title="论文简要 :"></a>论文简要 :</h1><ul><li>通过生成和遵循自然语言指令，本研究探索了一种表达复杂动作的分层决策方法。在一个挑战性的实时策略游戏环境中，通过收集人类玩家的指令和执行数据集，训练了指导者和执行者模型，并证明了使用自然语言作为潜在变量的模型明显优于直接模仿人类动作的模型。语言的组合结构对于动作表示的有效性至关重要。</li></ul><h1 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息:"></a>背景信息:</h1><ul><li>论文背景: 复杂问题可以自然地分解为高层规划和低层控制的步骤，但规划表示是具有挑战性的。本研究通过使用自然语言指令作为复杂动作的表达方式，解决了规划表示的挑战性问题。</li><li>过去方案: 传统的强化学习环境（如Atari或网格世界）对于规划在不同抽象级别上的作用并不适用。手动设计的宏操作通常无法与强大的人类表现相匹配。因此，需要一种新的方法来表示复杂动作。</li><li>论文的Motivation: 本研究的动机是利用自然语言指令作为复杂动作的表达方式。自然语言可以表达任意目标，并具有组合结构，可以实现对指令的泛化。通过将决策过程分解为规划和执行模块，并在它们之间引入自然语言接口，可以更好地解决复杂决策问题。</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202309041514911.png" alt="Snipaste_2023-09-04_15-12-53"></p><h1 id="方法-1"><a href="#方法-1" class="headerlink" title="方法:"></a>方法:</h1><ul><li>a. 理论背景:<ul><li>作者提出使用自然语言指令作为层次决策制定复杂动作的表示方法。他们开发了一个实时策略游戏环境，并从人类游戏中收集了一组指令执行对的数据。使用自然语言作为潜变量的模型优于直接模仿人类动作的模型。</li></ul></li><li>b. 技术路线:<ul><li>作者将复杂动作表示为自然语言指令，并引入了一个两级层次结构，其中高级指导模型为低级执行模型生成自然语言子目标。他们从实时策略游戏中收集了一组人类指令和执行的数据。</li></ul></li></ul><h1 id="结果-1"><a href="#结果-1" class="headerlink" title="结果:"></a>结果:</h1><ul><li><p>a. 详细的实验设置:</p><ul><li>作者介绍了基于MiniRTS的实时策略游戏环境。该游戏具有石头剪刀布单位攻击动态，并且具有大的状态-动作空间和部分可观察性的挑战。该游戏旨在对人类直观但对机器具有挑战性。</li></ul></li><li><p>b. 详细的实验结果:</p><ul><li>实验结果显示，当使用组合编码器（如词袋模型或循环神经网络模型）对指令进行编码时，执行模型的性能更好。使用组合指令编码器可以提高人类动作的可能性和与非层次执行模型（EXECUTORONLY）的胜率。指导模型在更结构化的指令模型下也显示出更好的可能性，特别是对于更大的指令集。结果表明，语言在表示复杂计划方面的潜力以及利用语言的组合结构进行泛化的重要性。</li></ul><h1 id=""><a href="#" class="headerlink" title=""></a></h1></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;LLM辅助RL-Agent决策&quot;&gt;&lt;a href=&quot;#LLM辅助RL-Agent决策&quot; class=&quot;headerlink&quot; title=&quot;LLM辅助RL Agent决策&quot;&gt;&lt;/a&gt;LLM辅助RL Agent决策&lt;/h1&gt;&lt;p&gt;在多智能体强化学习中，由于同时涉及时</summary>
      
    
    
    
    <category term="Code" scheme="http://holmodi.fun/categories/Code/"/>
    
    
    <category term="论文阅读" scheme="http://holmodi.fun/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    <category term="强化学习" scheme="http://holmodi.fun/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="LLM Agent" scheme="http://holmodi.fun/tags/LLM-Agent/"/>
    
  </entry>
  
  <entry>
    <title>土豆兄弟拆解01--基础词条、商店、独特的保底机制</title>
    <link href="http://holmodi.fun/posts/7374193e.html"/>
    <id>http://holmodi.fun/posts/7374193e.html</id>
    <published>2023-08-21T15:07:09.000Z</published>
    <updated>2023-08-27T19:28:38.691Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础词条"><a href="#基础词条" class="headerlink" title="基础词条"></a>基础词条</h1><h3 id="轮次"><a href="#轮次" class="headerlink" title="轮次"></a><strong>轮次</strong></h3><p>游戏一共有20波，第一波20s，随后每波时间+5s，20波90s</p><h3 id="敌人"><a href="#敌人" class="headerlink" title="敌人"></a><strong>敌人</strong></h3><table><thead><tr><th>字段</th><th align="center">描述</th></tr></thead><tbody><tr><td>行为</td><td align="center">行为组合，例如追逐玩家、随机移动、成群出现、靠近玩家时自动远离，远程攻击等等。精英怪的行为会存在几个阶段的变异，当血量小于一定值时切换行为模式。</td></tr><tr><td>血量 hp</td><td align="center">基础血量</td></tr><tr><td>+hp&#x2F;wave</td><td align="center">每波血量加值</td></tr><tr><td>移动速度</td><td align="center">部分怪物会在范围内随机，其余全局固定</td></tr><tr><td>伤害dmg</td><td align="center">基础伤害值</td></tr><tr><td>+dmg&#x2F;wave</td><td align="center">每波伤害加值</td></tr><tr><td>资源掉落数</td><td align="center">钱</td></tr><tr><td>箱子掉落率</td><td align="center">道具</td></tr><tr><td>回复道具掉落率</td><td align="center">回血</td></tr><tr><td>最早出现波次</td><td align="center"></td></tr><tr><td>ID</td><td align="center">程序内置ID</td></tr></tbody></table><p>敌人最大值：游戏中有最大100个敌人的上限，当刷新敌人总数超过这个数值时，会随机的让地图上的非精英怪死亡，这种方式死亡的敌人不会掉落材料，但可以触发道具击杀敌人的效果，如游戏里的赛博球(敌人死亡时有概率对另一个敌人造成伤害)</p><h3 id="玩家"><a href="#玩家" class="headerlink" title="玩家"></a><strong>玩家</strong></h3><p>玩家属性游戏里的描述比较详细，同时最近策划的游戏用不到这么复杂的玩家属性，这里就不扒了。</p><h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a><strong>升级</strong></h3><p>土豆里比较独特的点是获得金钱时会提供等额的经验XP，也就是金钱和XP的获取数额完全相同，但一个用于累计经验升级一个用于消费。</p><p><strong>💡 升级所需经验公式</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XP Required = (Level + <span class="number">3</span>)*(Level + <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p><strong>怪物掉落率折扣</strong>：</p><p>另外，怪物的材料掉落率在第五波开始会逐渐下降，控制了后期怪多时玩家能从怪物身上获取的经验&#x2F;XP数额。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308280021816.png" alt="image-20230828002132740"></p><p><strong>升级获取内容</strong>：</p><p>每当玩家升级时会依据稀有度分布刷新四个基础属性增益，具体刷新规则参考商店拆解，详细数据如下</p><table><thead><tr><th>Stat</th><th>I</th><th>II</th><th>III</th><th align="center">IV</th></tr></thead><tbody><tr><td>Max HP</td><td>3</td><td>6</td><td>9</td><td align="center">12</td></tr><tr><td>HP Regeneration</td><td>2</td><td>3</td><td>4</td><td align="center">5</td></tr><tr><td>Life Steal</td><td>1</td><td>2</td><td>3</td><td align="center">4</td></tr><tr><td>Damage</td><td>5</td><td>8</td><td>12</td><td align="center">16</td></tr><tr><td>Melee Damage</td><td>2</td><td>4</td><td>6</td><td align="center">8</td></tr><tr><td>Ranged Damage</td><td>1</td><td>2</td><td>3</td><td align="center">4</td></tr><tr><td>Elemental Damage</td><td>1</td><td>2</td><td>3</td><td align="center">4</td></tr><tr><td>Attack Speed</td><td>5</td><td>10</td><td>15</td><td align="center">20</td></tr><tr><td>Crit Chance</td><td>3</td><td>5</td><td>7</td><td align="center">9</td></tr><tr><td>Engineering Stat</td><td>2</td><td>3</td><td>4</td><td align="center">5</td></tr><tr><td>Range Stat</td><td>15</td><td>30</td><td>45</td><td align="center">60</td></tr><tr><td>Armor</td><td>1</td><td>2</td><td>3</td><td align="center">4</td></tr><tr><td>Dodge Stat</td><td>3</td><td>6</td><td>9</td><td align="center">12</td></tr><tr><td>Speed Stat</td><td>3</td><td>6</td><td>9</td><td align="center">12</td></tr><tr><td>Luck</td><td>5</td><td>10</td><td>15</td><td align="center">20</td></tr><tr><td>Harvesting</td><td>5</td><td>8</td><td>10</td><td align="center">12</td></tr></tbody></table><h1 id="商店"><a href="#商店" class="headerlink" title="商店"></a>商店</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>轮次结束时出现，每次刷新提供四个随机物品，物品的品质基于角色当前的幸运值和当前波次。每个物品被购买后当前格变为空白。玩家可以花费材料刷新商店，此时物品和空白格会被新物品替代，除非当前物品被玩家锁定。物品的价格、商店刷新价格都受到波数和玩家属性的影响。</p><h2 id="刷新"><a href="#刷新" class="headerlink" title="刷新"></a>刷新</h2><p>玩家可以花费材料刷新商店，每次刷新展示<strong>四件物品，</strong>此时已存在物品格和空白格会被新物品替代，除非当前物品被玩家锁定。</p><h3 id="一次刷新各道具出现概率"><a href="#一次刷新各道具出现概率" class="headerlink" title="一次刷新各道具出现概率"></a>一次刷新各道具出现概率</h3><p>每波刷新道具和武器概率分布</p><ul><li>道具: 65%</li><li>武器: 35%</li></ul><p><strong>道具的稀有度数值</strong></p><table><thead><tr><th align="center"></th><th>Available From Wave</th><th>Min Wave</th><th>Base Chance</th><th>+Chance per Wave</th><th>Max Chance</th></tr></thead><tbody><tr><td align="center">Tier 1</td><td>1</td><td>1</td><td>100%</td><td>0%</td><td>100%</td></tr><tr><td align="center">Tier 2</td><td>2</td><td>1</td><td>0</td><td>6%</td><td>60%</td></tr><tr><td align="center">Tier 3</td><td>4</td><td>3</td><td>0</td><td>2%</td><td>25%</td></tr><tr><td align="center">Tier 4</td><td>8</td><td>7</td><td>0</td><td>0.23%</td><td>8%</td></tr></tbody></table><p><code>((Chance per Wave * (Current Wave - Min Wave)) + Base Chance) * (100%+Luck)</code>  ，但不会超过Max Chance</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308272202932.png" alt="Untitled"></p><p>这里计算一下曲线能分析出土豆兄弟里面幸运收益还是偏低的，同时波数对稀有度的影响又比较高，只有在第10波到16波这个区间能得到明显优于0幸运的收益，导致除了主幸运的角色其他角色拿幸运道具影响不是太大。</p><h3 id="刷新价格增量"><a href="#刷新价格增量" class="headerlink" title="刷新价格增量"></a>刷新<strong>价格增量</strong></h3><p>刷新会让刷新价格上升，在轮次结束商店重新开启时这个增量会重置。</p><p><strong>💡 刷新价格增量</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Reroll Increase=times*<span class="built_in">Rounddown</span>(<span class="built_in">max</span>(<span class="number">0.5</span> * wave,<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p><strong>💡刷新价格基数</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">刷新价格基数:Wave + Reroll Increase</span><br></pre></td></tr></table></figure><p>基于以上公式可以获取到前20波的详细刷新价格</p><table><thead><tr><th align="center">波次</th><th>价格增量</th><th>价格基数</th></tr></thead><tbody><tr><td align="center">1</td><td>1</td><td>2</td></tr><tr><td align="center">2</td><td>1</td><td>3</td></tr><tr><td align="center">3</td><td>1</td><td>4</td></tr><tr><td align="center">4</td><td>2</td><td>6</td></tr><tr><td align="center">5</td><td>2</td><td>7</td></tr><tr><td align="center">6</td><td>3</td><td>9</td></tr><tr><td align="center">7</td><td>3</td><td>10</td></tr><tr><td align="center">8</td><td>4</td><td>12</td></tr><tr><td align="center">9</td><td>4</td><td>13</td></tr><tr><td align="center">10</td><td>5</td><td>15</td></tr><tr><td align="center">11</td><td>5</td><td>16</td></tr><tr><td align="center">12</td><td>6</td><td>18</td></tr><tr><td align="center">13</td><td>6</td><td>19</td></tr><tr><td align="center">14</td><td>7</td><td>21</td></tr><tr><td align="center">15</td><td>7</td><td>22</td></tr><tr><td align="center">16</td><td>8</td><td>24</td></tr><tr><td align="center">17</td><td>8</td><td>25</td></tr><tr><td align="center">18</td><td>9</td><td>27</td></tr><tr><td align="center">19</td><td>9</td><td>28</td></tr><tr><td align="center">20</td><td>N&#x2F;A</td><td>N&#x2F;A</td></tr></tbody></table><h3 id="💡-售价"><a href="#💡-售价" class="headerlink" title="💡 售价"></a>💡 售价</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Final Price =  (Base_Price + Wave + (Base_Price * <span class="number">0.1</span> * Wave)) * Shop_Price</span><br></pre></td></tr></table></figure><p>折扣道具会在最终售价基础上折扣</p><h2 id="保底机制（特殊刷新）"><a href="#保底机制（特殊刷新）" class="headerlink" title="保底机制（特殊刷新）"></a>保底机制（特殊刷新）</h2><blockquote><p><strong>这是土豆区别与其他同类游戏的一个独特机制，从玩家视角来看就是自己玩某一流派就比较容易刷出自己流派的道具和武器，让土豆在前中期刷新次数和打钱能力较低时能快速构建一套基础build的可能性比较高，在rouge类里保证了一定的前期体验。</strong></p></blockquote><h3 id="Item-Tags（针对65-道具刷新）"><a href="#Item-Tags（针对65-道具刷新）" class="headerlink" title="Item Tags（针对65%道具刷新）"></a>Item <strong>Tags（针对65%道具刷新）</strong></h3><p>  土豆里的每一个角色都会自带几个wanted tags，每一个道具都会附带几个Item tags，游戏中当前游玩的角色会更容易刷出与其相符的tags道具。具体算法如下：每当商品格刷新时，有65%的概率刷新道具，如果当前是道具，有5%的概率从tag池中刷新（这个tag池是角色tag池和物品tag池的交集)，否则从全道具池刷。</p><h3 id="武器、Class池（针对35-武器刷新）"><a href="#武器、Class池（针对35-武器刷新）" class="headerlink" title="武器、Class池（针对35%武器刷新）"></a>武器、Class池（针对35%武器刷新）</h3><p><strong>武器池刷新保底机制</strong>：前6波里前两次商店刷新必刷2个武器+两个道具，随后的3,4,5次刷新1个武器+3概率分布刷新（另外锁两个武器下拨就必刷两道具，以此类推）。第6波之后刷新按概率分布。</p><p>每个武器都有自带的Class（就是游戏里凑几个加额外数值的词条，枪支、中世纪武器之类的）。</p><p>当刷武器时，按以下概率分布出现：</p><ul><li><p>20% 相同武器：出现与玩家已持有的武器</p></li><li><p>15% 同Class武器：与当前已有武器class词条相同的武器</p></li><li><p>65% 全武器池</p></li></ul><p>此外，前五波<strong>同class武器池</strong>的刷新有奖励概率，具体表格如下。</p><table><thead><tr><th>Shop(Wave)</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>…</th><th>6 - 20</th></tr></thead><tbody><tr><td>% Bonus</td><td>12.5</td><td>10</td><td>7.5</td><td>5</td><td>2.5</td><td>…</td><td>-</td></tr><tr><td>% Bonus + Base (15%)</td><td>27.5</td><td>25</td><td>22.5</td><td>20</td><td>17.5</td><td>…</td><td>15</td></tr></tbody></table><p>综上，前五波大概率能拿满六把同种或同Class武器，如果想玩单一武器追求高等级的话选择单Class词条武器收益是很高的。</p><p><strong>升级刷新保底机制</strong>:在固定轮次中会100%刷出指定稀有度的升级项：</p><table><thead><tr><th align="center">Level</th><th>Tier</th><th>Percentage</th></tr></thead><tbody><tr><td align="center">1</td><td>Tier 1</td><td>100%</td></tr><tr><td align="center">5</td><td>Tier 2</td><td>100%</td></tr><tr><td align="center">10</td><td>Tier 3</td><td>100%</td></tr><tr><td align="center">15</td><td>Tier 3</td><td>100%</td></tr><tr><td align="center">20</td><td>Tier 3</td><td>100%</td></tr><tr><td align="center">25</td><td>Tier 4</td><td>100%</td></tr></tbody></table><p>再看一眼上面基础幸运下的刷新率,在没有保底情况下概率都低了一半，所以每五级的升级是需要多刷拿需求属性的，另外第五波的平均等级为7级。</p><blockquote><p><strong>在武器池刷新保底和升级刷新保底(看上面一次刷新道具出现概率，前几波刷新必出两武器)，Item Tags保底，在三个保底机制的共同作用下，前六波大部分玩家能刷出自己想要的构筑，并且五波之后的怪物掉落率也会下降。换个角度说土豆的前五波是设计师设计好的构筑阶段，需要玩家在前期花钱购买并确定装备构筑，大部分流派前面攒钱后面花都是不合理的。</strong></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基础词条&quot;&gt;&lt;a href=&quot;#基础词条&quot; class=&quot;headerlink&quot; title=&quot;基础词条&quot;&gt;&lt;/a&gt;基础词条&lt;/h1&gt;&lt;h3 id=&quot;轮次&quot;&gt;&lt;a href=&quot;#轮次&quot; class=&quot;headerlink&quot; title=&quot;轮次&quot;&gt;&lt;/a&gt;&lt;stro</summary>
      
    
    
    
    <category term="Games" scheme="http://holmodi.fun/categories/Games/"/>
    
    
    <category term="游戏拆解" scheme="http://holmodi.fun/tags/%E6%B8%B8%E6%88%8F%E6%8B%86%E8%A7%A3/"/>
    
    <category term="土豆兄弟" scheme="http://holmodi.fun/tags/%E5%9C%9F%E8%B1%86%E5%85%84%E5%BC%9F/"/>
    
  </entry>
  
  <entry>
    <title>GPT多轮对话CMAEL框架阅读+复现</title>
    <link href="http://holmodi.fun/posts/26e8bcc3.html"/>
    <id>http://holmodi.fun/posts/26e8bcc3.html</id>
    <published>2023-08-21T14:46:59.000Z</published>
    <updated>2023-08-21T15:03:05.512Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GPT多轮对话CMAEL框架阅读-复现"><a href="#GPT多轮对话CMAEL框架阅读-复现" class="headerlink" title="GPT多轮对话CMAEL框架阅读+复现"></a>GPT多轮对话CMAEL框架阅读+复现</h1><ul><li>Title: CAMEL: Communicative Agents for \Mind\ Exploration of Large Scale Language Model Society (CAMEL: 大规模语言模型社会的“心智”探索中的交流代理)</li><li>URLs: <a href="https://www.camel-ai.org/">Paper</a>, <a href="https://github.com/lightaime/camel">GitHub</a></li></ul><h1 id="概述"><a href="#概述" class="headerlink" title="概述 :"></a>概述 :</h1><ul><li>本文提出了一种名为CAMEL的多代理交流框架，旨在探索大规模语言模型多Agent的自主合作。通过使用角色扮演和内部提示来自主引导通信代理完成任务，同时保持与人类意图的一致性。研究结果表明，CAMEL可以生成对话数据，用于研究交流代理的行为和能力。</li><li>论文尝试解决GPT Agents在合作过程中面临的以下几个问题：<ul><li>多轮对话中的角色翻转角色翻转：多轮对话的过程中Gpt会忘记自己的身份，指令的执行者有时会反过来发出指令</li><li>助手重复指令：执行指令的助手角色对话过程中不执行却重复或转述已发出的指令</li><li>控制消息的有限循环：在多GPT多轮对话中给出中断信号，控制有限步长内解决任务。</li><li>flake replies不准确的回答：有时助理角色依据指令给出的解答方案不够准确，需要鉴别并重新生成。</li></ul></li></ul><h1 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息:"></a>背景信息:</h1><ul><li>论文背景: 随着对话和基于聊天的语言模型的快速发展，复杂任务解决取得了显著进展。然而，这些模型的成功很大程度上依赖于人类输入来引导对话，这可能具有挑战性且耗时。本文旨在探索构建可扩展技术以促进交流代理之间的自主合作，并洞察其“认知”过程的潜力。</li><li>过去方案: 过去的方法中，人类输入是引导对话的关键，但这需要用户提供相关和准确的提示，这对于缺乏领域专业知识的个体来说可能是困难的。因此，本文提出了一个关键问题：能否用一个能够在没有人类监督的情况下引导对话并完成任务的自主交流代理来取代人类干预？</li><li>为了解决这个问题，有必要进行更多的研究，探索完全自主完成任务的交流代理的潜力、能力和局限性。同时，还需要考虑多个代理之间的相互作用，因为这对于预测人工智能的未来至关重要。</li></ul><h1 id="方法"><a href="#方法" class="headerlink" title="方法:"></a>方法:</h1><ul><li>本文提出了一种名为角色扮演的交流代理框架。框架包括两个GPT Agent，一个<strong>AI助手</strong>和一个<strong>AI用户</strong>。开始时真实用户为此次给出大致的idea，Agent会先进行一次头脑风暴将此idea扩充并具体化成一个可执行的想法，AI用户根据此具体化的想法一步步生成可行的解决方案指令，而AI助手则在每一步指令下回应给出解决方案，AI用户会判断当前的解决方案是否合理，在确保合理后再进入下一轮循环。对话持续进行，直到AI用户判断当前任务已经完成，给出终止符号<CAMEL_TASK_DONE>或达到对话上限。</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308212242352.png" alt="Untitled"></p><ul><li>与对话语言模型的其他技术不同，论文里的提示工程仅在角色扮演开始时进行，用于任务指定和角色分配，随后的多轮对话都发生在两个Agent之间。文中给出的提示词示例，文中将这种模式称为Inception Prompting，大致就是有一个总结出通用的模板提示，后面实际用的时候做一些字符串处理将部分关键词替换成用户实际使用的。下图在初始化阶段给各个角色赋予的提示词示例。</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308212243826.png" alt="Untitled"></p><h1 id="结果"><a href="#结果" class="headerlink" title="结果:"></a>结果:</h1><ul><li><p>实验设置:</p><ul><li>使用LLM模型生成AI Society和Code两个数据集，以减少人类参与生成过程。</li><li>对于每个角色组合，生成50个助手角色、50个用户角色和10个任务，共生成了25000个对话。</li><li>对于每个语言和领域的组合，生成了20种编程语言、50个领域和50个任务，共生成了50000个对话。</li><li>在分析生成的数据集过程中，发现了角色翻转、助手重复指令、无效回复和无限对话循环等挑战。</li><li>对话终止的条件包括用户连续3轮不给助手指令、助手给用户指令、用户表示任务完成、达到令牌限制和达到最大消息数。</li></ul></li><li><p>实验结果:</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308212243761.png" alt="Untitled"></p></li><li><ul><li>对AI Society和Code数据集的对话终止原因进行了分析。AI Society数据集的主要终止原因是助手指令，而Code数据集的主要终止原因是令牌限制。观察到包含代码的回复往往较长，导致由于令牌限制而终止的次数更多。两个数据集中由于最大消息数而终止的次数较少，表明40条最大消息限制是合理的。</li><li>研究了启动提示设计对对话终止分布的影响。进行了两个启动提示修改：Prompt V2去除了助手回应格式，Prompt V1 + Task Planner在原始提示的基础上添加了任务规划器。这两个修改都显著增加了以任务令牌结束的对话数量，并减少了助手指令的消息数量。然而，与原始Prompt V1相比，Prompt V2和Prompt V1 + Task Planner的无效消息数量显著增加。</li><li>可视化了AI Society和Code数据集的指令和任务的信息地图。AI Society数据集涵盖了广泛的主题，包括生活方式、社交媒体、内容创作和软件开发。任务包括提供支持、分析、培训和头脑风暴。Code数据集涵盖了与广泛人群相关的主题，包括情感分析、语言和数据处理、数据收集和机器学习。</li></ul><hr><h1 id="复现"><a href="#复现" class="headerlink" title="复现"></a>复现</h1><p>使用LangChain框架，先实现一个CAMELAgent</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CAMELAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        system_message: SystemMessage,</span></span><br><span class="line"><span class="params">        model: AzureChatOpenAI,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.system_message = system_message</span><br><span class="line">        self.model = model</span><br><span class="line">        self.init_messages()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.init_messages()</span><br><span class="line">        <span class="keyword">return</span> self.stored_messages</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_messages</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.stored_messages = [self.system_message]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_messages</span>(<span class="params">self, message: BaseMessage</span>) -&gt; <span class="type">List</span>[BaseMessage]:</span><br><span class="line">        self.stored_messages.append(message)</span><br><span class="line">        <span class="keyword">return</span> self.stored_messages</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        input_message: HumanMessage,</span></span><br><span class="line"><span class="params">    </span>) -&gt; AIMessage:</span><br><span class="line">        messages = self.update_messages(input_message)</span><br><span class="line"></span><br><span class="line">        output_message = self.model(messages)</span><br><span class="line">        self.update_messages(output_message)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_message</span><br></pre></td></tr></table></figure><p>然后依据论文里的提示词模板调整实现inception prompt基础模板。</p><p>将模板和自定义的几个关键词组合形成初始化时用于引导两个Agent对话的基础代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_sys_msgs</span>(<span class="params">assistant_role_name: <span class="built_in">str</span>, user_role_name: <span class="built_in">str</span>, task: <span class="built_in">str</span></span>):</span><br><span class="line">    assistant_sys_template = SystemMessagePromptTemplate.from_template(</span><br><span class="line">        template=assistant_inception_prompt</span><br><span class="line">    )</span><br><span class="line">    assistant_sys_msg = assistant_sys_template.format_messages(</span><br><span class="line">        assistant_role_name=assistant_role_name,</span><br><span class="line">        user_role_name=user_role_name,</span><br><span class="line">        task=task,</span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    user_sys_template = SystemMessagePromptTemplate.from_template(</span><br><span class="line">        template=user_inception_prompt</span><br><span class="line">    )</span><br><span class="line">    user_sys_msg = user_sys_template.format_messages(</span><br><span class="line">        assistant_role_name=assistant_role_name,</span><br><span class="line">        user_role_name=user_role_name,</span><br><span class="line">        task=task,</span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> assistant_sys_msg, user_sys_msg</span><br></pre></td></tr></table></figure><p>最后基于user_sys_msg assistant_sys_msg创建两个示例，在循环中互相对话即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">user_msg = HumanMessage(</span><br><span class="line">    content=(</span><br><span class="line">        <span class="string">f&quot;<span class="subst">&#123;user_sys_msg.content&#125;</span>. &quot;</span></span><br><span class="line">        <span class="string">&quot;Now start to give me introductions one by one. &quot;</span></span><br><span class="line">        <span class="string">&quot;Only reply with Instruction and Input.&quot;</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">assistant_msg = HumanMessage(content=<span class="string">f&quot;<span class="subst">&#123;assistant_sys_msg.content&#125;</span>&quot;</span>)</span><br><span class="line">assistant_msg = assistant_agent.step(user_msg)</span><br><span class="line">chat_turn_limit, n = <span class="number">30</span>, <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> n &lt; chat_turn_limit:</span><br><span class="line">    n += <span class="number">1</span></span><br><span class="line">    user_ai_msg = user_agent.step(assistant_msg)</span><br><span class="line">    user_msg = HumanMessage(content=user_ai_msg.content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;AI User (<span class="subst">&#123;user_role_name&#125;</span>):\n\n<span class="subst">&#123;user_msg.content&#125;</span>\n\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    assistant_ai_msg = assistant_agent.step(user_msg)</span><br><span class="line">    assistant_msg = HumanMessage(content=assistant_ai_msg.content)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;AI Assistant (<span class="subst">&#123;assistant_role_name&#125;</span>):\n\n<span class="subst">&#123;assistant_msg.content&#125;</span>\n\n&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;&lt;CAMEL_TASK_DONE&gt;&quot;</span> <span class="keyword">in</span> user_msg.content:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h4 id="之前LangChain的这一段实现有Bug，复现的时候把bug修好上传发起pull-request二十分钟不到就被merge了🤣"><a href="#之前LangChain的这一段实现有Bug，复现的时候把bug修好上传发起pull-request二十分钟不到就被merge了🤣" class="headerlink" title="之前LangChain的这一段实现有Bug，复现的时候把bug修好上传发起pull request二十分钟不到就被merge了🤣"></a>之前LangChain的这一段实现有Bug，复现的时候把bug修好上传发起pull request二十分钟不到就被merge了🤣</h4><p><a href="https://github.com/langchain-ai/langchain/commit/89a8121eaa1796f6cfdc1853678a8517acfdee19">https://github.com/langchain-ai/langchain/commit/89a8121eaa1796f6cfdc1853678a8517acfdee19</a></p><hr><p>本地运作输出结果，这里试的是写一个flappy bird</p><p>D:\Env\anaconda\python.exe C:\Users\Administrator\PycharmProjects\GPTProj\camel.py<br>Specified task: Develop a flappy bird game in Python using Pygame. The game should feature a bird avatar that player can fly by tapping; pipes as obstacles to dodge; and a scoring system to count the number of pipes successfully passed.<br>Original task prompt:<br>Develop a flappy bird with pygame</p><p>Specified task prompt:<br>Develop a flappy bird game in Python using Pygame. The game should feature a bird avatar that player can fly by tapping; pipes as obstacles to dodge; and a scoring system to count the number of pipes successfully passed.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Start by installing the Pygame library.<br>Input: None</p><p>AI User (Game Designer):</p><p>Solution: To install the Pygame library, you can use pip, which is a package manager for Python. Here is the command you need to run in your terminal or command prompt:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pygame</span><br></pre></td></tr></table></figure><p>If you are using a version of Python 3, you might need to use pip3 instead:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pygame</span><br></pre></td></tr></table></figure><p>This command will download and install the Pygame library on your system. Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Create a window for the game.<br>Input: The window size should be 288x512 pixels.</p><p>AI User (Game Designer):</p><p>Solution: To create a window for the game using Pygame, we first need to initialize Pygame and then set the window size. Here is how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we first import the Pygame library and initialize it with <code>pygame.init()</code>. Then we set the dimensions of the game window to 288x512 pixels. The <code>pygame.display.set_mode()</code> function is used to create the game window.</p><p>The game loop is used to keep the game window open until the user closes it. It checks for a QUIT event, which occurs when the user closes the window, and sets <code>running</code> to False to exit the loop when that happens. Finally, <code>pygame.quit()</code> is called to close the Pygame window.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Create a bird avatar for the game.<br>Input: The bird avatar should be placed in the middle of the window.</p><p>AI User (Game Designer):</p><p>Solution: To create a bird avatar, we first need an image file for the bird. Once we have that, we can load it into our game using Pygame’s <code>pygame.image.load()</code> function. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird image</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird image</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line"></span><br><span class="line">    # Draw the bird on the window</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we first load the bird image using <code>pygame.image.load()</code>. Then we get the dimensions of the bird image using the <code>get_width()</code> and <code>get_height()</code> methods. We calculate the position of the bird to place it in the middle of the window. In the game loop, we draw the bird on the window using the <code>blit()</code> method of the game window, and then we update the display with <code>pygame.display.update()</code>.</p><p>Please replace ‘bird.png’ with the path to your bird image file.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Implement the functionality for the bird to move up when the player taps.<br>Input: The bird should move up by 10 pixels each tap.</p><p>AI User (Game Designer):</p><p>Solution: To make the bird move up when the player taps, we can listen for a KEYDOWN event in our game loop. When a KEYDOWN event occurs, we can check if the key that was pressed is the space bar, and if it is, we move the bird up by 10 pixels. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird image</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird image</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line">        elif event.type == pygame.KEYDOWN:</span><br><span class="line">            if event.key == pygame.K_SPACE:</span><br><span class="line">                bird_y -= 10  # Move the bird up by 10 pixels</span><br><span class="line"></span><br><span class="line">    # Draw the bird on the window</span><br><span class="line">    game_window.fill((0, 0, 0))  # Fill the window with black to clear the old frame</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we added an additional check in our event loop to listen for KEYDOWN events. When a KEYDOWN event occurs, we check if the key that was pressed is the space bar (pygame.K_SPACE), and if it is, we subtract 10 from bird_y to move the bird up by 10 pixels. We also added a call to <code>game_window.fill((0, 0, 0))</code> before drawing the bird, to clear the old frame before drawing the new one.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Implement the functionality for the bird to fall down due to gravity.<br>Input: The bird should fall down by 5 pixels every frame.</p><p>AI User (Game Designer):</p><p>Solution: To simulate gravity, we can add a constant value to the bird’s y-coordinate every frame. This will make the bird fall down over time. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird image</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird image</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line">        elif event.type == pygame.KEYDOWN:</span><br><span class="line">            if event.key == pygame.K_SPACE:</span><br><span class="line">                bird_y -= 10  # Move the bird up by 10 pixels</span><br><span class="line"></span><br><span class="line">    bird_y += 5  # Simulate gravity by moving the bird down by 5 pixels every frame</span><br><span class="line"></span><br><span class="line">    # Draw the bird on the window</span><br><span class="line">    game_window.fill((0, 0, 0))  # Fill the window with black to clear the old frame</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we added <code>bird_y += 5</code> after the event loop. This line of code is executed every frame, regardless of whether any events occurred, so it will make the bird fall down by 5 pixels every frame.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Create pipes as obstacles for the bird to dodge.<br>Input: The pipes should be placed randomly along the y-axis and move from right to left.</p><p>AI User (Game Designer):</p><p>Solution: To create pipes as obstacles, we need an image for the pipes. We can then create a list of pipes, where each pipe is a dictionary with ‘x’, ‘y’, and ‘passed’ keys. ‘x’ and ‘y’ are the coordinates of the pipe, and ‘passed’ is a boolean that indicates whether the bird has passed the pipe. We can then move the pipes from right to left by subtracting from their ‘x’ coordinate every frame. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird and pipe images</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line">pipe = pygame.image.load(&#x27;pipe.png&#x27;)  # Replace &#x27;pipe.png&#x27; with the path to your pipe image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird image</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Create a list of pipes</span><br><span class="line">pipes = [&#123;&#x27;x&#x27;: window_width, &#x27;y&#x27;: random.randint(0, window_height - pipe.get_height()), &#x27;passed&#x27;: False&#125; for _ in range(5)]</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line">        elif event.type == pygame.KEYDOWN:</span><br><span class="line">            if event.key == pygame.K_SPACE:</span><br><span class="line">                bird_y -= 10  # Move the bird up by 10 pixels</span><br><span class="line"></span><br><span class="line">    bird_y += 5  # Simulate gravity by moving the bird down by 5 pixels every frame</span><br><span class="line"></span><br><span class="line">    # Move the pipes</span><br><span class="line">    for p in pipes:</span><br><span class="line">        p[&#x27;x&#x27;] -= 5</span><br><span class="line">        if p[&#x27;x&#x27;] + pipe.get_width() &lt; 0:  # If the pipe is no longer visible</span><br><span class="line">            p[&#x27;x&#x27;] = window_width  # Move it back to the right side of the window</span><br><span class="line">            p[&#x27;y&#x27;] = random.randint(0, window_height - pipe.get_height())  # Give it a new random height</span><br><span class="line">            p[&#x27;passed&#x27;] = False  # Reset the &#x27;passed&#x27; status</span><br><span class="line"></span><br><span class="line">    # Draw the bird and the pipes on the window</span><br><span class="line">    game_window.fill((0, 0, 0))  # Fill the window with black to clear the old frame</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line">    for p in pipes:</span><br><span class="line">        game_window.blit(pipe, (p[&#x27;x&#x27;], p[&#x27;y&#x27;]))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we first load the pipe image. Then we create a list of pipes, where each pipe is a dictionary with ‘x’, ‘y’, and ‘passed’ keys. In the game loop, we move the pipes by subtracting from their ‘x’ coordinate, and if a pipe is no longer visible, we move it back to the right side of the window and give it a new random height. We also draw the pipes on the window in the same way we draw the bird.</p><p>Please replace ‘pipe.png’ with the path to your pipe image file.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Implement a scoring system to count the number of pipes successfully passed.<br>Input: The score should increase by 1 for each pipe passed.</p><p>AI User (Game Designer):</p><p>Solution: To implement a scoring system, we can add a ‘score’ variable that starts at 0. Then, in our game loop, we can check for each pipe if the bird has passed it, and if it has, we increase the score by 1 and set the ‘passed’ key of the pipe to True to prevent the score from increasing again for the same pipe. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird and pipe images</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line">pipe = pygame.image.load(&#x27;pipe.png&#x27;)  # Replace &#x27;pipe.png&#x27; with the path to your pipe image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird image</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Create a list of pipes</span><br><span class="line">pipes = [&#123;&#x27;x&#x27;: window_width, &#x27;y&#x27;: random.randint(0, window_height - pipe.get_height()), &#x27;passed&#x27;: False&#125; for _ in range(5)]</span><br><span class="line"></span><br><span class="line"># Initialize the score</span><br><span class="line">score = 0</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line">        elif event.type == pygame.KEYDOWN:</span><br><span class="line">            if event.key == pygame.K_SPACE:</span><br><span class="line">                bird_y -= 10  # Move the bird up by 10 pixels</span><br><span class="line"></span><br><span class="line">    bird_y += 5  # Simulate gravity by moving the bird down by 5 pixels every frame</span><br><span class="line"></span><br><span class="line">    # Move the pipes and check if the bird passed any pipes</span><br><span class="line">    for p in pipes:</span><br><span class="line">        p[&#x27;x&#x27;] -= 5</span><br><span class="line">        if p[&#x27;x&#x27;] + pipe.get_width() &lt; bird_x and not p[&#x27;passed&#x27;]:</span><br><span class="line">            p[&#x27;passed&#x27;] = True</span><br><span class="line">            score += 1</span><br><span class="line">        if p[&#x27;x&#x27;] + pipe.get_width() &lt; 0:  # If the pipe is no longer visible</span><br><span class="line">            p[&#x27;x&#x27;] = window_width  # Move it back to the right side of the window</span><br><span class="line">            p[&#x27;y&#x27;] = random.randint(0, window_height - pipe.get_height())  # Give it a new random height</span><br><span class="line">            p[&#x27;passed&#x27;] = False  # Reset the &#x27;passed&#x27; status</span><br><span class="line"></span><br><span class="line">    # Draw the bird and the pipes on the window</span><br><span class="line">    game_window.fill((0, 0, 0))  # Fill the window with black to clear the old frame</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line">    for p in pipes:</span><br><span class="line">        game_window.blit(pipe, (p[&#x27;x&#x27;], p[&#x27;y&#x27;]))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">    print(f&#x27;Score: &#123;score&#125;&#x27;)  # Print the score</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we added a ‘score’ variable that starts at 0. In the game loop, we added a check for each pipe to see if the bird has passed it, and if it has, we increase the score by 1 and set the ‘passed’ key of the pipe to True. We also print the score after updating the display.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><p>Instruction: Implement a game over condition when the bird hits a pipe or the ground.<br>Input: The game should stop and display a “Game Over” message when the game over condition is met.</p><p>AI User (Game Designer):</p><p>Solution: To implement a game over condition, we can add a collision check in our game loop. If the bird’s rectangle intersects with a pipe’s rectangle or the bird’s y-coordinate is greater than the window height, we set <code>running</code> to False to end the game. We can then display a “Game Over” message using Pygame’s font module. Here’s how you can do it:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">import pygame</span><br><span class="line">import random</span><br><span class="line"></span><br><span class="line"># Initialize Pygame</span><br><span class="line">pygame.init()</span><br><span class="line"></span><br><span class="line"># Set the dimensions of the game window</span><br><span class="line">window_width = 288</span><br><span class="line">window_height = 512</span><br><span class="line">game_window = pygame.display.set_mode((window_width, window_height))</span><br><span class="line"></span><br><span class="line"># Load the bird and pipe images</span><br><span class="line">bird = pygame.image.load(&#x27;bird.png&#x27;)  # Replace &#x27;bird.png&#x27; with the path to your bird image file</span><br><span class="line">pipe = pygame.image.load(&#x27;pipe.png&#x27;)  # Replace &#x27;pipe.png&#x27; with the path to your pipe image file</span><br><span class="line"></span><br><span class="line"># Get the dimensions of the bird and pipe images</span><br><span class="line">bird_width = bird.get_width()</span><br><span class="line">bird_height = bird.get_height()</span><br><span class="line">pipe_width = pipe.get_width()</span><br><span class="line">pipe_height = pipe.get_height()</span><br><span class="line"></span><br><span class="line"># Calculate the position of the bird to place it in the middle of the window</span><br><span class="line">bird_x = (window_width - bird_width) / 2</span><br><span class="line">bird_y = (window_height - bird_height) / 2</span><br><span class="line"></span><br><span class="line"># Create a list of pipes</span><br><span class="line">pipes = [&#123;&#x27;x&#x27;: window_width, &#x27;y&#x27;: random.randint(0, window_height - pipe_height), &#x27;passed&#x27;: False&#125; for _ in range(5)]</span><br><span class="line"></span><br><span class="line"># Initialize the score</span><br><span class="line">score = 0</span><br><span class="line"></span><br><span class="line"># Create a font object for the game over message</span><br><span class="line">font = pygame.font.Font(None, 36)</span><br><span class="line"></span><br><span class="line"># Game loop to keep the window open</span><br><span class="line">running = True</span><br><span class="line">while running:</span><br><span class="line">    for event in pygame.event.get():</span><br><span class="line">        if event.type == pygame.QUIT:</span><br><span class="line">            running = False</span><br><span class="line">        elif event.type == pygame.KEYDOWN:</span><br><span class="line">            if event.key == pygame.K_SPACE:</span><br><span class="line">                bird_y -= 10  # Move the bird up by 10 pixels</span><br><span class="line"></span><br><span class="line">    bird_y += 5  # Simulate gravity by moving the bird down by 5 pixels every frame</span><br><span class="line"></span><br><span class="line">    # Move the pipes and check if the bird passed any pipes or collided with a pipe</span><br><span class="line">    for p in pipes:</span><br><span class="line">        p[&#x27;x&#x27;] -= 5</span><br><span class="line">        if p[&#x27;x&#x27;] + pipe_width &lt; bird_x and not p[&#x27;passed&#x27;]:</span><br><span class="line">            p[&#x27;passed&#x27;] = True</span><br><span class="line">            score += 1</span><br><span class="line">        if p[&#x27;x&#x27;] &lt; bird_x + bird_width and p[&#x27;x&#x27;] + pipe_width &gt; bird_x and p[&#x27;y&#x27;] &lt; bird_y + bird_height and p[&#x27;y&#x27;] + pipe_height &gt; bird_y:</span><br><span class="line">            running = False  # End the game if the bird collided with a pipe</span><br><span class="line">        if p[&#x27;x&#x27;] + pipe_width &lt; 0:  # If the pipe is no longer visible</span><br><span class="line">            p[&#x27;x&#x27;] = window_width  # Move it back to the right side of the window</span><br><span class="line">            p[&#x27;y&#x27;] = random.randint(0, window_height - pipe_height)  # Give it a new random height</span><br><span class="line">            p[&#x27;passed&#x27;] = False  # Reset the &#x27;passed&#x27; status</span><br><span class="line"></span><br><span class="line">    if bird_y + bird_height &gt; window_height:</span><br><span class="line">        running = False  # End the game if the bird hit the ground</span><br><span class="line"></span><br><span class="line">    # Draw the bird and the pipes on the window</span><br><span class="line">    game_window.fill((0, 0, 0))  # Fill the window with black to clear the old frame</span><br><span class="line">    game_window.blit(bird, (bird_x, bird_y))</span><br><span class="line">    for p in pipes:</span><br><span class="line">        game_window.blit(pipe, (p[&#x27;x&#x27;], p[&#x27;y&#x27;]))</span><br><span class="line"></span><br><span class="line">    # Update the display</span><br><span class="line">    pygame.display.update()</span><br><span class="line"></span><br><span class="line">    print(f&#x27;Score: &#123;score&#125;&#x27;)  # Print the score</span><br><span class="line"></span><br><span class="line"># Display the game over message</span><br><span class="line">text = font.render(&#x27;Game Over&#x27;, True, (255, 255, 255))</span><br><span class="line">game_window.blit(text, ((window_width - text.get_width()) / 2, (window_height - text.get_height()) / 2))</span><br><span class="line">pygame.display.update()</span><br><span class="line"></span><br><span class="line">pygame.quit()</span><br></pre></td></tr></table></figure><p>In this code, we added a collision check for each pipe in the game loop. If the bird’s rectangle intersects with a pipe’s rectangle, we set <code>running</code> to False to end the game. We also added a check to see if the bird hit the ground, and if it did, we also end the game. After the game loop, we display a “Game Over” message in the middle of the window.</p><p>Next request.</p><p>AI Assistant (Python Programmer):</p><CAMEL_TASK_DONE></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;GPT多轮对话CMAEL框架阅读-复现&quot;&gt;&lt;a href=&quot;#GPT多轮对话CMAEL框架阅读-复现&quot; class=&quot;headerlink&quot; title=&quot;GPT多轮对话CMAEL框架阅读+复现&quot;&gt;&lt;/a&gt;GPT多轮对话CMAEL框架阅读+复现&lt;/h1&gt;&lt;ul&gt;
</summary>
      
    
    
    
    
    <category term="论文阅读" scheme="http://holmodi.fun/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    <category term="LLM" scheme="http://holmodi.fun/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>强化学习关卡测试论文阅读2</title>
    <link href="http://holmodi.fun/posts/ed103377.html"/>
    <id>http://holmodi.fun/posts/ed103377.html</id>
    <published>2023-08-06T13:12:46.000Z</published>
    <updated>2023-08-06T13:47:08.137Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Sestini-Alessandro-Joakim-Bergdahl-Konrad-Tollmar-Andrew-D-Bagdanov和Linus-Gisslen-《Towards-Informed-Design-and-Validation-Assistance-in-Computer-Games-Using-Imitation-Learning》"><a href="#Sestini-Alessandro-Joakim-Bergdahl-Konrad-Tollmar-Andrew-D-Bagdanov和Linus-Gisslen-《Towards-Informed-Design-and-Validation-Assistance-in-Computer-Games-Using-Imitation-Learning》" class="headerlink" title="Sestini, Alessandro, Joakim Bergdahl, Konrad Tollmar, Andrew D Bagdanov和Linus Gisslén. 《Towards Informed Design and Validation Assistance in Computer Games Using Imitation Learning》,"></a>Sestini, Alessandro, Joakim Bergdahl, Konrad Tollmar, Andrew D Bagdanov和Linus Gisslén. 《Towards Informed Design and Validation Assistance in Computer Games Using Imitation Learning》,</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在游戏开发和许多其他领域中，由于系统规模的不断增长和手动测试变得不可行，设计验证和测试成为一个重大挑战。本文提出了一种新的自动游戏验证方法。我们的方法利用数据驱动的模仿学习技术，这种方法需要很少的努力和时间，无需机器学习或编程知识，设计师可以使用这种方法高效地训练游戏测试代理程序。我们通过与行业专家进行用户研究来验证我们的方法的有效性。调查结果显示，我们的方法确实是一种有效的游戏验证方法，并且数据驱动的编程将有助于减少工作量并提高现代游戏测试的质量。调查还强调了一些尚未解决的挑战。借助最新的文献资料，我们分析了这些挑战，并提出了未来研究方向，以最大化我们方法的效用。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110810.png" alt="Untitled"></p><p>文章主要验证了一种HILL（Human-In-the-Loop Learning）的自动关卡测试流程，可以大致概括为设计师在沙盒里搭建一个关卡，自己试玩几遍保存数据，通过IL算法，基于数据训练一个agent模仿已有轨迹，之后可以调整关卡摆放，让agent来验证关卡设计的合理性。</p><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p><strong>算法</strong>：DAgger</p><p><strong>状态空间</strong>：基础的Gamerplay数据，如是否在地面、是否在攀爬，文章里没有给全，以及标准化的当前到目标点的向量，还有一个没描述清楚但比较关键的是composed of the R2 projections of the agent-to-goal vector onto the XY and XZ planes，这个也没具体解释是什么意思，根据文章里面这张图推测应该是agent面前有两个平面，目标点到agent的射线穿过这个平面是的接触点被编码为1，其他点是0。</p><p><strong>模型：</strong>图上c所示模型</p><h2 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a>实验流程</h2><p><strong><strong><strong><strong><strong><strong>环境搭建：</strong></strong></strong></strong></strong></strong>搭建一个带有程序化生成元素的3d沙盒地图，设计师可以自行调整目标点位置，关卡布局，中间目标点以及动态元素。Agent使用离散动作空间，有向前移动，向后移动，右转，左转，跳跃，射击，什么都不做 7个基础动作，在交互物体旁有与场景交互动作。</p><p><strong>培训目标：衡量算法的泛化成功率，轨迹相似度量，目标达成率</strong></p><ul><li><strong>泛化成功率：</strong>验证IL代理能否实时验证变动的关卡布局。先通过IL训练模型，然后调整关卡摆放，观察agent如何适应这些更改，以验证设计的有效性。</li><li><strong>验证复杂轨迹:</strong> 构建一条复杂轨迹，文中示例包括使用电梯，与按钮交互，射击破坏墙体，到达目标位置，验证算法是否能快速学习专家示例。</li><li><strong>目标达成率：</strong>在一个地图中记录演示到达目标位置的导航数据并训练模型，然后每隔几秒将agent随机放在地图上的一个位置，测试能否自主到达目标。</li></ul><h2 id="User-Study"><a href="#User-Study" class="headerlink" title="User Study"></a>User Study</h2><p>通过在线问卷的方式获取调查结果，问题由Likert question和开放问题组成，调查分为四个部分:</p><p>第一部分要求参与者提供一些背景信息;</p><p>第二个问题是询问他们当前的游戏验证工作流程，特别是他们是否使用手动或自动测试;</p><p>第三，作为调查的主要部分，询问参与者对我们的解决方案的看法，他们是否会在自己的游戏中使用它，代理人&#x2F;方法应该具备什么特征来帮助他们在游戏和关卡设计工作中发挥作用，他们是否认为IL能够帮助他们创造出更好的游戏;</p><p>第四个可选问题包括还有哪些可能的use case以及对未来方向的建议。</p><h2 id="未来方向："><a href="#未来方向：" class="headerlink" title="未来方向："></a>未来方向：</h2><p><strong>泛化</strong>:代理不仅能学会专家的演示行为，还能进一步去代表大部分用户可能会采取的自然行为，代理的训练更一般化，同时具有更高的探索水平。</p><p><strong>代理个性Personas</strong>:能够训练具有不同性格的agent，创造类似不同种类玩家的多性格代理。</p><p><strong>探索：</strong>Agent能够在模仿的同时具备探索被忽视问题的能力。</p><p><strong>Usability</strong>：文中认为的重要改进方向，让整个工具的使用流程和实用度提升，让不懂机器学习的设计师也能获取到关于他们训练模型的可用信息，同时改善整个工具的易用性。</p><p><strong>多代理：</strong>目前大部分游戏都需要multi-agent验证，目前研究还停留在单智能体对单一示例学习上。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这篇论文中，我们声称通过模仿学习的数据驱动编程是适用于实时验证游戏和关卡设计的一种合适方法。我们提出了一种模仿学习方法，并研究了其性能，重点关注三种不同的设计验证用例。我们的实验展示了与利用强化学习或基于模型的脚本化行为的方法相比，这种方法在满足有效的游戏设计工具需求方面的优势。我们还与来自不同游戏工作室和游戏类型的专业游戏和关卡设计师进行了用户研究。我们询问参与者评估在日常工作流程中使用这种方法的可取性和改进机会。此外，我们还询问设计师希望从数据驱动的工具中获得哪些特性，以用于创建验证其设计的自主代理。</p><p>用户研究突显了设计师希望有一种自动化的方式来测试和验证他们的游戏。除了我们的初步结果外，我们还展示了我们提出的数据驱动方法是实现这些目标的潜在候选方法。研究还强调了存在于文献技术和实际在游戏行业中应用之间的挑战和差距。因此，我们提出了一系列研究方向，以帮助这些方法从一个不切实际的工具发展成为一个有效的游戏设计工具。我们希望我们的建议能够鼓励游戏研究社区为这项研究做出贡献或扩展。</p><p>论文所用问卷：</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110049.png" alt="Untitled"></p><h1 id="Alonso-Eloi-Maxim-Peter-David-Goumard和Joshua-Romoff-《Deep-Reinforcement-Learning-for-Navigation-in-AAA-Video-Games》-arXiv-2020年11月17日-http-arxiv-org-abs-2011-04764"><a href="#Alonso-Eloi-Maxim-Peter-David-Goumard和Joshua-Romoff-《Deep-Reinforcement-Learning-for-Navigation-in-AAA-Video-Games》-arXiv-2020年11月17日-http-arxiv-org-abs-2011-04764" class="headerlink" title="Alonso, Eloi, Maxim Peter, David Goumard和Joshua Romoff. 《Deep Reinforcement Learning for Navigation in AAA Video Games》. arXiv, 2020年11月17日. http://arxiv.org/abs/2011.04764."></a>Alonso, Eloi, Maxim Peter, David Goumard和Joshua Romoff. 《Deep Reinforcement Learning for Navigation in AAA Video Games》. arXiv, 2020年11月17日. <a href="http://arxiv.org/abs/2011.04764">http://arxiv.org/abs/2011.04764</a>.</h1><h2 id="论文简要"><a href="#论文简要" class="headerlink" title="论文简要 :"></a>论文简要 :</h2><ul><li>本文提出了一种使用深度强化学习来实现视频游戏中非玩家角色导航的方法，通过学习如何在3D地图上使用各种导航能力，取代了传统的基于图形的导航方法，实现了在复杂环境中高效导航的目标。</li></ul><h2 id="背景信息"><a href="#背景信息" class="headerlink" title="背景信息:"></a>背景信息:</h2><ul><li>论文背景: 在视频游戏中，非玩家角色（NPC）的导航是提升玩家体验的重要组成部分，传统的导航方法使用导航网格（NavMesh）来表示地图，但对于具有复杂导航能力的NPC，NavMesh的复杂性使其难以应用于实际场景。</li><li>过去方案: 过去的解决方案包括使用路径规划算法和扩展NavMesh来处理角色的导航能力，但这些方法限制了NPC可以使用的导航能力，降低了NPC的真实感。</li><li>论文的Motivation: 为了解决传统导航方法的局限性，本文提出使用深度强化学习来学习如何使用各种导航能力在地图上导航，以取代传统的基于图形的导航方法。通过使用现代AAA视频游戏中的复杂3D环境进行测试，证明了该方法的有效性和高性能。</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法:"></a>方法:</h2><ul><li>a. 理论背景:<ul><li>本文研究了视频游戏中非玩家角色（NPCs）的导航问题。传统方法使用导航网格（NavMesh）来表示地图并找到位置之间的最短路径。然而，当处理像抓钩或传送等复杂导航能力时，NavMesh变得复杂且难以处理。作者提出使用深度强化学习（Deep RL）来学习如何使用任何导航能力导航3D地图。他们在Unity游戏引擎中的大型复杂3D环境中测试了他们的方法，并取得了很高的成功率。</li></ul></li><li>b. 技术路线:<ul><li>本文的方法旨在使用代理的可用导航能力解决固定3D地图上的点对点导航问题。系统架构包括一个共享的嵌入网络，用于处理输入，如3D占用地图、2D深度图和代理及其目标的绝对位置。提取的特征与其他状态变量（如相对目标位置、速度、加速度和先前动作）结合，然后通过线性层和LSTM传递，创建最终的嵌入，由策略和评论模型共享。该方法中的动作是连续的，对应跳跃、前进、横移和旋转。奖励被密集化以鼓励代理尽快接近目标并尽快到达。训练过程使用了一种离策略强化学习算法，称为soft 演员-评论家算法，评论家和策略网络共享从局部感知中提取嵌入的层，使用卷积神经网络和LSTM。训练使用burn-in来初始化隐藏状态，并使用训练课程逐渐增加难度。训练使用Adam优化器进行。</li></ul></li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110827.png" alt="Untitled"></p><h2 id="环境搭建-1"><a href="#环境搭建-1" class="headerlink" title="环境搭建"></a>环境搭建</h2><p><strong>观察空间</strong>：3d occumpancymap + 2d深度图+常规int vector类型agent信息（速度、相对位置、之前动作）</p><p><strong>动作空间：</strong>continuous：跳跃、前进、射击、转向。跳跃在输出时是连续动作，处理时按离散动作处理。</p><p><strong>奖励：</strong>除到达目标点之外，为防止奖励过于稀疏，每一步都会获得基于当前timestep的当前距目标点欧式距离奖励，在一定时间后没到点目标点给与惩罚。概括来说就是一个鼓励agent尽快靠近目标的值。</p><p>$$<br>R_t &#x3D; \max\left(\min_{\forall i \in [|0, t-1|]} D_i(\text{agent}, \text{goal}) - D_t(\text{agent}, \text{goal}), 0\right)^{D_t(\text{agent}, \text{goal})} + \alpha + 1\quad D_t(\text{agent}, \text{goal}) \leq \varepsilon<br>$$</p><p><strong>训练流程：</strong>初始阶段在地图选定一个点，在一个较小半径内随机生成agent和目标点，训练一定步数后扩大半径范围直到整个地图区域都被覆盖。</p><h2 id="结果"><a href="#结果" class="headerlink" title="结果:"></a>结果:</h2><ul><li><p>a. 详细的实验设置:</p><ul><li>实验在Unity游戏引擎上构建的Toy Map和Big Map上进行。Toy Map是一个小地图，用于说明现有导航解决方案的局限性，而Big Map是一个更大更复杂的环境，包含建筑物和不同的目标。在这两个地图上进行了两组消融实验：基于状态的消融和基于算法的消融。在基于状态的消融中，评估了没有BoxCasts、没有RayCasts、没有BoxCasts和RayCasts以及没有绝对位置的代理。在基于算法的消融中，将基准代理与没有LSTM、没有课程和使用分层经验回放（HER）进行训练的代理进行了比较。</li></ul><p>  <img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110073.png" alt="Untitled">  </p></li><li><p>b. 详细的实验结果:</p><ul><li>消融研究的结果显示，在最终课程级别上，基准代理在达到目标的成功率方面明显优于没有BoxCasts、没有RayCasts和没有BoxCasts和RayCasts的代理。从代理的状态中删除绝对位置不会对性能产生负面影响，并且实际上在Big Map上平均略有改善。然而，在Toy Map上，这种改善在统计上并不显著。通过RayCasts和BoxCasts实现的局部感知显著提高了深度强化学习系统的样本效率。LSTM组件在训练大型地图时对于样本效率的优化是至关重要的。算法消融实验表明，去除LSTM会显著降低Big Map上的样本效率。此外，去除训练课程会显著提高Big Map上的性能，但对Toy Map没有显著影响。与NavMesh的比较表明，深度强化学习系统可以处理导航动作，而无需手动指定单个链接。深度强化学习方法在所有测试场景中至少达到90%的成功率。</li></ul><p>  <img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110320.png" alt="Untitled"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Sestini-Alessandro-Joakim-Bergdahl-Konrad-Tollmar-Andrew-D-Bagdanov和Linus-Gisslen-《Towards-Informed-Design-and-Validation-Assistance</summary>
      
    
    
    
    <category term="Code" scheme="http://holmodi.fun/categories/Code/"/>
    
    
    <category term="论文阅读" scheme="http://holmodi.fun/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    <category term="强化学习" scheme="http://holmodi.fun/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>使用强化学习构建关卡设计辅助流程 草稿</title>
    <link href="http://holmodi.fun/posts/44375f7b.html"/>
    <id>http://holmodi.fun/posts/44375f7b.html</id>
    <published>2023-08-06T12:52:25.000Z</published>
    <updated>2023-08-06T13:43:26.623Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在游戏开发中，关卡设计是至关重要的一部分。一个好的关卡设计可以让游戏更加有趣、具有挑战性，甚至可以吸引更多的玩家。然而，设计一个好的关卡并不是一件容易的事情，需要设计师有丰富的经验和技能。</p><p>为了解决这个问题，我们设计并验证了一套基于强化学习的辅助关卡迭代流程。这个流程可以帮助设计师快速设计出更好的关卡，并提供实时的反馈，以便设计师可以及时调整关卡设计。</p><p>流程提供了一个合理的设计—验证—反馈循环。设计师可以与工具进行自然交互，将自己的需求和关卡必要知识传递给智能体，无需过多的工具学习成本和机器学习前置知识积累。通过智能体行为部分感知真实玩家在当前场景下的实际体验，设计师可以实时获取关于关卡的反馈。</p><p>训练的过程也是可交互的，设计师能自然的在关卡设计-关卡验证-反馈获取循环中切换。这个流程有较高的泛化能力，能在各种不同类型的游戏中辅助验证。</p></blockquote><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062113497.png" alt="Untitled"></p><p><strong>设计理念：</strong></p><ul><li>为关卡设计提供一个合理的 设计—验证—反馈 循环。</li><li>设计师能与工具自然交互，将自己的需求和关卡必要知识传递给智能体，无需过多的工具学习成本和机器学习前置知识积累。</li><li>设计师能实时获取关于关卡的反馈，通过智能体行为感知真实玩家在当前关卡下的实际体验。</li><li>训练过程是可交互的，设计师能自然的在 关卡设计-关卡验证-反馈获取 循环中切换。</li><li>有较高泛化能力，能在各种不同类型的游戏中辅助验证。</li></ul><h2 id="HIIL理论"><a href="#HIIL理论" class="headerlink" title="HIIL理论"></a>HIIL理论</h2><p>Human-In-the-Loop Learning(HILL)人在循环中的机器学习专注于将人类的知识和经验整合到机器学习过程中。它旨在通过融入人类专业知识来训练准确的预测模型，并以最小的成本实现。在机器学习的背景下，人在循环中涉及人类在各个阶段的积极参与，如数据处理、模型训练和推断，以及系统设计和应用。融合人类知识可以提高机器学习模型的性能，并解决机器学习所面临的挑战。人在循环中的机器学习是一个跨学科领域，涉及计算机科学、认知科学和心理学的交叉。近年来，它越来越受到重视，并在过去十年中得到广泛研究。人在循环中的研究目标是设计有效的解决方案，利用人类专业知识，以增强机器学习的自动化能力。</p><p>从人类反馈中进行强化学习（Reinforcement Learning from Human Feedback，简称RLHF）是一种将人类数据标签整合到基于强化学习的优化过程中的方法。它的动机是为了解决建模人类偏好的挑战。</p><p>本文的思路与RLHF正好相反，基于RL算法在关卡中的实际反馈，设计师可以动态的调整关卡设置，使其向更符合自己预定的游戏体验目标逼近。</p><blockquote><p>Human-in-the-loop refers to a research area that focuses on integrating human knowledge and experience into the machine learning process. It aims to train accurate prediction models with minimum cost by incorporating human expertise. In the context of machine learning, human-in-the-loop involves the active participation of humans in various stages, such as data processing, model training and inference, and system design and application. The integration of human knowledge can improve the performance of machine learning models and address the challenges posed by machine learning. Human-in-the-loop is an interdisciplinary field that intersects computer science, cognitive science, and psychology. It has gained increasing importance in recent years and has been extensively studied in the past decade. The goal of human-in-the-loop research is to design effective solutions that leverage human expertise to enhance the automation of machine learning.</p></blockquote><h2 id="RL辅助关卡设计的可行性分析"><a href="#RL辅助关卡设计的可行性分析" class="headerlink" title="RL辅助关卡设计的可行性分析"></a>RL辅助关卡设计的可行性分析</h2><p>强化学习智能体在游戏关卡中展现了出色的策略涌现能力<a href="https://openai.com/research/emergent-tool-use">[Emergent tool use from multi-agent interaction]</a>，经过一定的迭代轮次后，它能够发现许多设计师尚未预料到的游戏策略，从而在设计过程中辅助设计师进行优化和调整关卡策略设计。以OpenAI的Hide and Seek案例为例，智能体发现了一种影响游戏平衡的踩箱滑行策略，这是在常规的设计和测试阶段难以发现的问题。若在上线后被玩家发现，将对游戏平衡产生不利影响。</p><p>（后面再补充）</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062113670.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114416.png" alt="Untitled"></p><h2 id="RL辅助关卡迭代的初版流程示例"><a href="#RL辅助关卡迭代的初版流程示例" class="headerlink" title="RL辅助关卡迭代的初版流程示例"></a>RL辅助关卡迭代的初版流程示例</h2><p>基于近期个人开发过程中的实际流程，依据本文理论将其总结如下：</p><p><strong>设计</strong>：下图是模仿吃鸡游戏的城镇决赛圈场景设计的一个多智能体作战环境。游戏的体验目标类似于吃鸡，鼓励玩家多对枪，尽量避免出现避战苟鸡的情况，整个流程控制在10~30秒之间。在初版中，每个玩家拥有四发弹药，地图三个区域范围内在游戏开始时会随机位置刷新一批橙色小球，捡到地上的橙色小球就可以补充一发弹药，玩家被击中两次会被淘汰。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114940.png" alt="%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%9E%84%E5%BB%BA%E5%85%B3%E5%8D%A1%E8%AE%BE%E8%AE%A1%E8%BE%85%E5%8A%A9%E6%B5%81%E7%A8%8B%20%E8%8D%89%E7%A8%BF%2084749dc154274b949176bfe3769e3d29/Untitled%203.png"></p><p><strong>验证</strong>：在使用强化学习算法训练一定步骤后，Agent采取了以下策略：2~3个队友不断拾取自己附近的弹药并射击以快速清空地上的弹药资源，随后在墙角苟住等对面过来，其余的队友尝试绕后前往靠近对方的弹药刷新点清空弹药资源，双方都在尽力清空环境中的资源使得对手在用完自己能存储的四枚弹药之后就丧失战斗力。前期的缩在墙角清空弹药的行为使得整个流程超过一分钟，常常出现双方都没有弹药只能互相对视的情况。</p><p><strong>反馈：</strong> 当前的资源刷新设计和玩家弹药容量不符合游戏体验目标，玩家在当前情况下射击过于谨慎，此外垃圾时间太多。</p><p><strong>设计：</strong> 基于以上反馈，重新设置弹药刷新规则和玩家弹药数量。弹药：玩家拥有四个弹匣，每个弹匣25发弹药，打完需要时间换弹。空投：游戏开始后每10s随机在三个区域投放一轮，拾取后补充两个弹匣，地图中心区域会刷新特殊空投让拾取玩家伤害加一，鼓励玩家向地图中心聚集，同时调整两侧建筑物位置方便玩家绕后。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114401.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114919.png" alt="Untitled"></p><p><strong>验证：</strong>相同架构的模型在训练一致的步长后，Agent采取的策略明显激进许多。涌现出几种不同的对战策略：1：同时前往中路对枪，占领中心区域后配合架住四个方向。2：两人架住中路，一人绕后一人防绕后。3：四人分两队从两侧交叉火力进攻中路。部分情况下还会有藏角落建筑物后蹲守对方绕后玩家的情况出现。相比第一版地图这些改动较大影响了策略和玩法。不过当前地图在出现4v1的残局时最后一个玩家会躲藏在墙角架枪，导致敌方四个玩家花费10秒以上才能将其找出击败。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114545.png" alt="Untitled"></p><p><strong>反馈：</strong>当前地图在占据中路后很难拿到卡四在角落的对手信息，而主动前往搜寻又容易被提前架好的对手击败，因此常常出现残局一人躲角落四人站中路等待的情况。</p><p><strong>设计：</strong>调整掩体区域的联通情况，降低躲在拐角的安全度。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114356.png" alt="Untitled"></p><p><strong>验证：</strong>修改后游戏步长有了较为明显的下降，在同算法参数的情况下也能稳定在一个更短的时间范围内。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114303.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062114051.png" alt="Untitled"></p><p><strong>反馈：</strong>修改后的地图能较大增加对战的激烈程度，同时仍保留各类策略战术的涌现。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;在游戏开发中，关卡设计是至关重要的一部分。一个好的关卡设计可以让游戏更加有趣、具有挑战性，甚至可以吸引更多的玩家。然而，设计一个好的关卡并不是一件容易的事情，需要设计师有丰富的经验和技能。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，我们设计并验证了一套基于强</summary>
      
    
    
    
    <category term="Code" scheme="http://holmodi.fun/categories/Code/"/>
    
    
    <category term="强化学习" scheme="http://holmodi.fun/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="关卡设计" scheme="http://holmodi.fun/tags/%E5%85%B3%E5%8D%A1%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>强化学习关卡测试论文阅读1</title>
    <link href="http://holmodi.fun/posts/ec6151bc.html"/>
    <id>http://holmodi.fun/posts/ec6151bc.html</id>
    <published>2023-07-30T07:48:35.000Z</published>
    <updated>2023-08-06T13:43:28.234Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Lu-Cong-Raluca-Georgescu和Johan-Verwey-《Go-Explore-Complex-3D-Game-Environments-for-Automated-Reachability-Testing》-arXiv-2022年9月1日-http-arxiv-org-abs-2209-00570"><a href="#Lu-Cong-Raluca-Georgescu和Johan-Verwey-《Go-Explore-Complex-3D-Game-Environments-for-Automated-Reachability-Testing》-arXiv-2022年9月1日-http-arxiv-org-abs-2209-00570" class="headerlink" title="Lu, Cong, Raluca Georgescu和Johan Verwey. 《Go-Explore Complex 3D Game Environments for Automated Reachability Testing》. arXiv, 2022年9月1日. http://arxiv.org/abs/2209.00570."></a>Lu, Cong, Raluca Georgescu和Johan Verwey. 《Go-Explore Complex 3D Game Environments for Automated Reachability Testing》. arXiv, 2022年9月1日. <a href="http://arxiv.org/abs/2209.00570">http://arxiv.org/abs/2209.00570</a>.</h1><h2 id="Absract"><a href="#Absract" class="headerlink" title="Absract"></a>Absract</h2><p>现代AAA级视频游戏拥有庞大的游戏关卡和地图，对于关卡测试人员来说，这些地图日益难以进行彻底的覆盖。因此，游戏通常会出现严重的错误，比如玩家会从地板上掉下去，或者被卡在墙壁里。我们提出了一种针对模拟3D环境中可达性错误的方法，该方法基于强大的探索算法Go-Explore，该算法保存地图上的唯一检查点，然后从中选择有潜力的检查点进行探索。我们证明，当结合游戏导航网格的简单启发式方法时，Go-Explore能够发现复杂环境中具有挑战性的错误，并且无需人工示范或对游戏动态的了解。在覆盖导航网格和发现地图上的唯一位置方面，Go-Explore明显优于更复杂的基准算法，包括基于内在好奇心的强化学习。最后，由于我们使用了并行代理，我们的算法可以在单台计算机上在10小时内完全覆盖一个广阔的1.5km x 1.5km游戏世界，因此非常适用于持续测试套件。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062108274.png" alt="Untitled"></p><h2 id="核心贡献"><a href="#核心贡献" class="headerlink" title="核心贡献"></a>核心贡献</h2><ol><li>应用了一种简单高效的算法，Go-Explore，用于在具有挑战性的探索地图中发现可达位置，而无需人工示范或对游戏动态的了解。</li><li>提出了一种将发现的位置与游戏NavMesh进行比较，从而将其分类为预期和意外的标准。未探索的导航网格区域也可能被标记出来。</li><li>展示了通过在单个游戏实例中并行化代理，能够在单台计算机上在10小时内彻底覆盖广阔的1.5km x 1.5km游戏地图，使得我们的算法非常适用于持续测试套件。</li></ol><h2 id="强化学习中的探索"><a href="#强化学习中的探索" class="headerlink" title="强化学习中的探索"></a>强化学习中的探索</h2><h3 id="基于奖励函数"><a href="#基于奖励函数" class="headerlink" title="基于奖励函数"></a>基于奖励函数</h3><p>对于每一个空间状态赋予s，赋予值n(s)，在探索时每次到达此状态给予奖励r</p><p>$$<br>r_t &#x3D; \frac{1}{n(s)}<br>$$</p><p>但此方法难以处理状态空间较大的情况，并且利于并行计算加快训练速度。</p><h3 id="Random-Network-Distillation"><a href="#Random-Network-Distillation" class="headerlink" title="Random Network Distillation"></a>Random Network Distillation</h3><p>一种用于高维状态空间的探索奖励计算的灵活方法，通过估计一个固定随机初始化神经网络给出的游戏观察特征的预测误差来计算探索奖励。RND算法的基本思想是，使用一个随机初始化的神经网络来预测游戏观察的特征，然后使用另一个神经网络来预测这些特征的误差。探索奖励是由这个误差的大小来计算的。这种方法的优点是可以适用于高维状态空间，而且不需要对环境进行任何先验知识的假设。RND算法的一个缺点是需要训练两个神经网络，这可能会增加算法的计算成本。</p><h3 id="GoExplore算法"><a href="#GoExplore算法" class="headerlink" title="GoExplore算法"></a>GoExplore算法</h3><p>Go-Explore是解决难以探索问题的另一种方法，它维护先前探索过的状态的缓存，然后使用启发式方法周期性地选择有潜力的状态，并从这些状态进行探索。一旦找到了具有足够高回报的轨迹，就会使用模仿学习来使发现的行为更加稳健。该算法旨在避免“偏离轨道”的现象，在没有显式记忆的算法中，如RND，预测器网络可能会因为灾难性遗忘而丢失关于先前达到的状态的信息。在大型地图中，这种现象可能更容易发生。</p><ol><li>初始化：算法开始时，初始化一个已访问状态的地图和一个未探索状态的优先队列。优先队列按照每个状态被访问的次数排序，访问次数最少的状态具有最高的优先级。</li><li>探索：算法进入一个循环，重复选择优先级最高的未探索状态，并对其进行探索。为了探索一个状态，算法从该状态开始进行随机游走，直到到达一个之前未访问过的新状态。然后，算法将新状态添加到已访问地图和优先队列中。</li><li>缓存：为了避免重新访问已经探索过的状态，算法维护了一个已发现位置的缓存。如果算法遇到一个已经在缓存中的状态，它会跳过该状态的探索，并在当前状态和缓存状态之间添加一个链接。</li><li>回溯：如果算法到达了一个死路或已经探索过的状态，它会回溯到优先队列中最后一个未探索的状态，并从那里继续探索。</li><li>可达性测试：当算法探索游戏环境时，它会标记远离导航网格的已发现点。这有助于识别可达性问题并在地图上突出显示有问题的点。</li><li>连续测试：Go-Explore可以集成到连续测试框架中，以在每个级别更新时发现错误，并在质量保证方面节省大量资源。</li></ol><h2 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a>实验方法</h2><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062108512.png" alt="Untitled"></p><p>使用Unreal Engine 5设计的专有测试游戏关卡上评估了方法。考虑了三个难度逐渐增加的地图：</p><ul><li>小地图：一个小的测试区域，包含障碍物和两个有意放置的错误（约100米 x 100米）。</li><li>大地图：一个广阔的城市景观，用于测试每种算法的可扩展性（约1.5公里 x 1.5公里）。这个地图是现代自动化方法所考虑的最大地图之一。</li><li>遍历地图：一个具有挑战性几何结构的大型多层地图，用作难度较高的探索挑战。</li></ul><p>游戏使用丰富的3D观测数据，包括可选的<strong>射线投射、位置和旋转特征</strong>。代理使用与标准游戏手柄相匹配的多离散动作空间进行移动。这些地图在图2中有所说明。</p><p>对于Go-Explore，我们评估了前一节中描述的所有重置启发式方法——基于访问的、基于目标的和混合的。我们使用默认的距离阈值K &#x3D; 1来添加新的点，并且在评估代理在训练过程中访问了多少个唯一位置时使用相同的阈值。代理每隔t_reset &#x3D; 128步重置一次。首先，我们在三个测试地图上评估了Go-Explore与基准算法RND（使用Proximal Policy Optimization进行优化，Schulman等人，2017年）和随机探索的性能。接下来，我们消融了各种组件，首先表明Go-Explore对超参数选择稳定，其次，随机探索对大规模地图的强大性能至关重要。</p><p>对于每个实验，通过在每个地图内运行16个独立代理来加速训练，这些代理不能相互交互或看到对方。每个代理与中央的发现位置缓存进行同步。我们在小地图上进行了200,000个时间步的训练，在两个大地图上进行了10,000,000个时间步的训练，并使用4个随机种子重复每个实验。由于我们使用了并行化，小地图的墙钟时间约为30分钟，而大地图只需要在一台F8 Azure虚拟机上进行10小时的训练即可完成。对于RND基准算法，我们仅使用了GeForce RTX 2080 GPU。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>采用了一种不使用神经网络的方式解决地图遍历的问题，思路和深搜差不多，在地图上按一定间隔生成坐标点，探索到一个点就把附近一定距离内的点删了，再将仍然存在的点加入队列中。在本论文中，我们展示了Go-Explore算法能够在现代AAA级视频游戏中可扩展、高效且无需学习的情况下进行广阔的3D游戏地图可达性测试，而无需任何人工示范或对游戏动态的了解。与之前基于好奇心的强化学习方法相比，Go-Explore通过维护一个发现位置的缓存来避免灾难性遗忘的问题。Ecoffet等人（2019年）提倡的随机探索方法在实现上明显更简单，而且避免了使用神经网络。通过标记远离导航网格的发现位置，我们能够廉价地识别可达性问题，并突显地图上的问题点。由于算法运行快速且易于实现，我们预期Go-Explore可以轻松地整合到连续测试框架中。通过这样做，每个关卡在更新时都可能发现错误，并且在质量保证方面可能节省大量资源。</p><h1 id="Sestini-Alessandro-Linus-Gisslen-Joakim-Bergdahl-Konrad-Tollmar和Andrew-D-Bagdanov-《CCPT-Automatic-Gameplay-Testing-and-Validation-with-Curiosity-Conditioned-Proximal-Trajectories》-arXiv-2022年2月21日-http-arxiv-org-abs-2202-10057"><a href="#Sestini-Alessandro-Linus-Gisslen-Joakim-Bergdahl-Konrad-Tollmar和Andrew-D-Bagdanov-《CCPT-Automatic-Gameplay-Testing-and-Validation-with-Curiosity-Conditioned-Proximal-Trajectories》-arXiv-2022年2月21日-http-arxiv-org-abs-2202-10057" class="headerlink" title="Sestini, Alessandro, Linus Gisslén, Joakim Bergdahl, Konrad Tollmar和Andrew D. Bagdanov. 《CCPT: Automatic Gameplay Testing and Validation with Curiosity-Conditioned Proximal Trajectories》. arXiv, 2022年2月21日. http://arxiv.org/abs/2202.10057."></a>Sestini, Alessandro, Linus Gisslén, Joakim Bergdahl, Konrad Tollmar和Andrew D. Bagdanov. 《CCPT: Automatic Gameplay Testing and Validation with Curiosity-Conditioned Proximal Trajectories》. arXiv, 2022年2月21日. <a href="http://arxiv.org/abs/2202.10057">http://arxiv.org/abs/2202.10057</a>.</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>该论文提出了一种新颖的深度强化学习算法，用于在复杂的3D导航环境中进行自动分析和检测游戏问题。该算法名为Curiosity-Conditioned Proximal Trajectories（CCPT），它结合了好奇心学习和模仿学习，训练代理在从专家示范中得到的已知轨迹附近进行系统性探索。我们展示了CCPT如何在复杂环境中进行探索，发现游戏问题和设计缺陷，并直接向游戏设计师识别和强调这些问题。我们进一步在一个反映现代AAA级视频游戏复杂性的新颖3D导航环境中展示了该算法的有效性。我们的结果显示，CCPT相比基准方法具有更高的覆盖率和更多的错误发现，因此可以为游戏设计师提供一个有价值的自动识别游戏设计问题的工具。</p><h2 id="导航模型"><a href="#导航模型" class="headerlink" title="导航模型"></a>导航模型</h2><p>agent观察到的状态由以下内容组成：以3D语义占用地图的形式的局部感知(conv3d)，以及agent物理属性的标量信息（全局位置，是否在地面上，是否附着在可攀爬表面上，是否可以执行二段跳，速度和方向）。</p><p>全局位置使用positional embeddings编码生成:</p><p>$$<br>PE_{(pos, 2i)} &#x3D; \sin\left(\frac{pos}{10000^{(2i&#x2F;d)}}\right)<br>$$</p><p>$$<br>PE_{(pos, 2i+1)} &#x3D; \cos\left(\frac{pos}{10000^{(2i&#x2F;d)}}\right)<br>$$</p><p>文章认为在3D场景中仅仅使用归一化的坐标或learned embeddings时网络不足以理解不同状态之间的区别</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062109460.png" alt="Untitled"></p><p>最后将这些信息concatenanted送入网络</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062109634.png" alt="Untitled"></p><p>在图中，展示了作为网络输入的示例3D语义地图。这些地图是对空间和代理周围元素的分类离散化表示，每个体素由该位置上对象的语义整数值来定义。给予的唯一外部奖励是当代理到达一个活动目标时，每个step都会获得+10的奖励。由于在如此庞大的环境中奖励非常稀疏，代理很难获得一个非零的奖励，因此训练非常困难。此外，仅有外部奖励的话，即使代理学会到达目标位置，它们也会始终遵循相同的轨迹而不去探索新路径。相反，我们需要代理能够在继续寻找未探索路径的同时，高效地到达目标区域，因此将探索和模仿的奖励结合起来。</p><h2 id="模仿学习模型"><a href="#模仿学习模型" class="headerlink" title="模仿学习模型"></a>模仿学习模型</h2><p>使用基于GAIL算法基础上构建的AMP算法，给定一组专家演示M，目标是学习衡量策略与演示之间的相似性，然后通过前向强化学习更新策略。目标被建模为一个判别器D(s, a)，用于预测一个给定的状态-动作对(s, a)是否来自演示集或者是由运行策略生成的。AMP采用了最小二乘GAN [Mao等人，2017]提出的损失函数</p><p>$$<br>L_{\text{AMP}} &#x3D; \arg \min_D \mathbb{E}<em>{d_M(s,a) } \left[ (D(s, a) - 1)^2 \right] + \mathbb{E}</em>{d_{\pi}(s,a)} \left[ (D(s, a) + 1)^2 \right]<br>$$</p><h2 id="好奇心模型"><a href="#好奇心模型" class="headerlink" title="好奇心模型"></a>好奇心模型</h2><blockquote><p>前置：RND网络<br>RND这类文章是基于强化学习在解决Atari游戏中蒙德祖玛的复仇的困境提出的。由于在这类游戏中存在非常稀疏的奖励，Agent在探索利用上存在很大的问题。RND提出了一种只需要做前向传播就能很好计算得到的探索奖励，使用agent过去的经验的预测误差来估计新经验探索性的启发，RND使用了一个确定的随机初始化的神经网络，来预测当前状态的输出，进而确定这个探索奖励。<br>总奖励值为：<strong>extrinsic reward + intrinsic reward，其中extrinsic reward是由环境给与的，反应设计者的意图，原始奖励，intrinsic reward是算法为了达到最终目标而学习到的有益行为。</strong></p><p>从设计方面来看，<strong>intrinsic reward function是一个带参数的需要在训练过程中优化的目标函数，而非人为设计的某一种计算方式；</strong></p><p>从目的方面来看，<strong>intrinsic reward function是想让智能体自己学到应当是要做一件什么事情（what to do)，而不是通过辅助式的设计告诉它如何做（how to do）</strong></p><p>RND使用随机网络和预测网络的误差值来计算intrinsic reward，鼓励agent更多在环境中进行探索。</p></blockquote><p>这里基于RND网络的基础上将奖励函数设置为：</p><p>$$<br>R(s_t, a_t) &#x3D; \alpha \cdot r_c(s_{t+1}) + (1 - \alpha) \cdot r_i(s_t, a_t) + r_e(s_t, a_t)<br>$$</p><p>将好奇心奖励和模仿学习奖励按比例加起来作为intrinsic reward，再加上环境的<strong>extrinsic reward。</strong></p><p>α ∈ [0, 1] i在每一轮训练开始时随机初始化一个值，使得算法随机在模仿学习和探索中采样。</p><h2 id="好奇心驱动探索"><a href="#好奇心驱动探索" class="headerlink" title="好奇心驱动探索"></a>好奇心驱动探索</h2><p>好奇心驱动探索的流程如下：</p><ol><li>首先，CCPT使用专家演示来指导智能体的探索，以便智能体能够更快地学习到期望的行为。</li><li>然后，有意识地探索期望轨迹的附近。CCPT使用一个称为“探索条件内在奖励函数”的函数来驱动探索。这个函数会根据智能体的行为和环境的状态来计算一个奖励值，以鼓励智能体探索未知的区域。</li><li>接下来，CCPT使用深度强化学习来训练智能体，以便智能体能够自主地探索和学习。在训练过程中，智能体会不断地尝试新的行为，并根据探索条件内在奖励函数的奖励值来调整自己的行为。</li><li>最后，CCPT使用并行训练来提高训练效率，以便智能体能够更快地学习到期望的行为。在并行训练中，多个智能体会同时进行训练，以便更快地收敛到最优解。</li></ol><p>通过这个流程，CCPT能够有意识地探索期望轨迹的附近，并帮助游戏设计师自动检测复杂3D游戏场景中的错误和问题。</p><h2 id="测试问题路径"><a href="#测试问题路径" class="headerlink" title="测试问题路径"></a>测试问题路径</h2><p>首先将α &gt;0.5的路径筛选出来，即依据好奇心算法探索的路径，再将其中平均奖励大于指定阈值的路径显示在地图上，这些一般都是测试过程中发现的问题路径。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/202308062110070.png" alt="Untitled"></p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>在本文中，我们介绍了一种新颖的强化学习方法，用于自动化测试复杂的3D场景。”Curiosity-Conditioned Proximal Trajectories”（CCPT）允许开发人员和设计师通过专家演示来指定测试区域。CCPT使用模仿学习和好奇心的组合，由我们称之为”exploration-conditioned intrinsic reward function”驱动，在展示轨迹的附近进行探索。我们的方法不仅能够发现故障和疏漏，还能够自动识别和突出显示包含潜在问题的轨迹。我们的结果在提出的导航环境中显示出高水平的覆盖率和错误发现，证明好奇心和模仿的特定组合对此目的非常有效。我们相信，这个算法将成为AAA游戏设计师的有用工具，可以自动识别问题或潜在的漏洞，减少对人工测试人员的依赖。</p><p>CCPT应用于自动化游戏玩法分析的一个限制是我们必须为每个要测试的区域执行一个实验。一种可能的解决方案是提供大量的演示，并同时测试不同的区域。然而，众所周知，基于GAN的方法在拟合大数据集时容易出现模式崩溃（mode collapse）。在这种情况下，策略可能只模仿一小部分示例行为，从而仅专注于一个区域。另一个缺点是CCPT不能保证在环境中找到所有的错误和问题。特别是，那些与专家演示相距较远的问题可能被我们的代理程序错过。我们正在尝试的一个可能的解决方案是在第一次迭代中使用发现的问题轨迹作为专家演示执行另一次CCPT迭代：由于它们涉及相同的区域，策略将不会受到模式崩溃的影响，同时增加探索性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Lu-Cong-Raluca-Georgescu和Johan-Verwey-《Go-Explore-Complex-3D-Game-Environments-for-Automated-Reachability-Testing》-arXiv-2022年9月1日-h</summary>
      
    
    
    
    <category term="Code" scheme="http://holmodi.fun/categories/Code/"/>
    
    
    <category term="论文阅读" scheme="http://holmodi.fun/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    <category term="强化学习" scheme="http://holmodi.fun/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>强化学习多人FPS训练记录</title>
    <link href="http://holmodi.fun/posts/18650ffe.html"/>
    <id>http://holmodi.fun/posts/18650ffe.html</id>
    <published>2023-06-30T07:46:04.000Z</published>
    <updated>2023-08-06T13:43:20.815Z</updated>
    
    <content type="html"><![CDATA[<h2 id="训练环境搭建"><a href="#训练环境搭建" class="headerlink" title="训练环境搭建"></a>训练环境搭建</h2><blockquote><p>Version information:<br>ml-agents: 0.30.0,<br>ml-agents-envs: 0.30.0,<br>Communicator API: 1.5.0,<br>PyTorch: 2.0.1+cu117</p></blockquote><p>训练命令行输入：</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mlagents-learn ./DodgeBall.yaml --run-id=fifthrun --initialize-<span class="keyword">from</span>=fouthRun --resume</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>值</th></tr></thead><tbody><tr><td>trainer_type</td><td>poca</td></tr><tr><td>batch_size</td><td>2048</td></tr><tr><td>buffer_size</td><td>20480</td></tr><tr><td>learning_rate</td><td>0.0003</td></tr><tr><td>beta</td><td>0.005</td></tr><tr><td>epsilon</td><td>0.2</td></tr><tr><td>lambd</td><td>0.95</td></tr><tr><td>num_epoch</td><td>3</td></tr><tr><td>learning_rate_schedule</td><td>constant</td></tr><tr><td>beta_schedule</td><td>constant</td></tr><tr><td>epsilon_schedule</td><td>constant</td></tr><tr><td>normalize</td><td>False</td></tr><tr><td>hidden_units</td><td>512</td></tr><tr><td>num_layers</td><td>3</td></tr><tr><td>vis_encode_type</td><td>simple</td></tr><tr><td>memory</td><td>None</td></tr><tr><td>goal_conditioning_type</td><td>none</td></tr><tr><td>deterministic</td><td>False</td></tr><tr><td>gamma</td><td>0.999</td></tr><tr><td>strength</td><td>1.0</td></tr><tr><td>normalize</td><td>False</td></tr><tr><td>hidden_units</td><td>128</td></tr><tr><td>num_layers</td><td>2</td></tr><tr><td>vis_encode_type</td><td>simple</td></tr><tr><td>memory</td><td>None</td></tr><tr><td>goal_conditioning_type</td><td>hyper</td></tr><tr><td>deterministic</td><td>False</td></tr><tr><td>init_path</td><td>None</td></tr><tr><td>keep_checkpoints</td><td>40</td></tr><tr><td>checkpoint_interval</td><td>2000000</td></tr><tr><td>max_steps</td><td>500000000</td></tr><tr><td>time_horizon</td><td>1000</td></tr><tr><td>summary_freq</td><td>50000</td></tr><tr><td>threaded</td><td>False</td></tr><tr><td>save_steps</td><td>500000</td></tr><tr><td>team_change</td><td>1000000</td></tr><tr><td>swap_steps</td><td>200000</td></tr><tr><td>window</td><td>100</td></tr><tr><td>play_against_latest_model_ratio</td><td>0.5</td></tr><tr><td>initial_elo</td><td>1200.0</td></tr><tr><td>behavioral_cloning</td><td>None</td></tr></tbody></table><h3 id="训练场景"><a href="#训练场景" class="headerlink" title="训练场景"></a>训练场景</h3><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/image-20230730155641248.png" alt="image-20230730155641248"></p><p><strong>场景定义：</strong></p><p>外围墙体+障碍物墙体+空投补给。</p><p>蓝色空投补给10s刷新，补充所有子弹，黄色补充所有子弹同时武器伤害+1。</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/image-20230730155653415.png" alt="image-20230730155653415"></p><p>输入数据与y轴无关，将九个场景垂直放置加快训练速度</p><h2 id="智能体设置"><a href="#智能体设置" class="headerlink" title="智能体设置"></a>智能体设置</h2><p>血量：2</p><p>基础攻击：1</p><p>冲刺CD：1</p><p>移动速度：20</p><p>冲刺移速：30</p><h3 id="智能体sensor设置"><a href="#智能体sensor设置" class="headerlink" title="智能体sensor设置"></a>智能体sensor设置</h3><ul><li><p>弹药传感器：检测射击的弹道和空投弹药箱</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/image-20230730155734511.png" alt="image-20230730155734511"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/image-20230730155742471.png" alt="image-20230730155742471"></p></li><li><p>人物传感器：检测队友、对手以及他们的朝向</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25204.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25205.png" alt="Untitled"></p></li><li><p>墙体传感器：检测障碍物</p></li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25206.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25207.png" alt="Untitled"></p><ul><li>背后信息传感器</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25208.png" alt="Untitled"></p><p>最终结果：</p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%25209.png" alt="Untitled"></p><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/Untitled%252010.png" alt="Untitled"></p><ul><li><p>BufferSensor</p><ul><li><p>存储其余队友的PlayerInfo，最大8×3</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">PlayerInfo</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">public</span> DodgeBallAgent Agent;</span><br><span class="line">            <span class="keyword">public</span> <span class="built_in">int</span> HitPointsRemaining;</span><br><span class="line">            [<span class="meta">HideInInspector</span>]</span><br><span class="line">            <span class="keyword">public</span> Vector3 StartingPos;</span><br><span class="line">            [<span class="meta">HideInInspector</span>]</span><br><span class="line">            <span class="keyword">public</span> Quaternion StartingRot;</span><br><span class="line">            [<span class="meta">HideInInspector</span>]</span><br><span class="line">            <span class="keyword">public</span> Rigidbody Rb;</span><br><span class="line">            [<span class="meta">HideInInspector</span>]</span><br><span class="line">            <span class="keyword">public</span> Collider Col;</span><br><span class="line">            [<span class="meta">HideInInspector</span>]</span><br><span class="line">            <span class="keyword">public</span> <span class="built_in">int</span> TeamID;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="built_in">float</span>[] <span class="title">GetOtherAgentData</span>(<span class="params">DodgeBallGameController.PlayerInfo info</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">var</span> otherAgentdata = <span class="keyword">new</span> <span class="built_in">float</span>[<span class="number">8</span>];</span><br><span class="line">            otherAgentdata[<span class="number">0</span>] = (<span class="built_in">float</span>)info.Agent.HitPointsRemaining / (<span class="built_in">float</span>)NumberOfTimesPlayerCanBeHit;</span><br><span class="line">            <span class="keyword">var</span> relativePosition = transform.InverseTransformPoint(info.Agent.transform.position);</span><br><span class="line">            otherAgentdata[<span class="number">1</span>] = relativePosition.x / m_LocationNormalizationFactor;</span><br><span class="line">            otherAgentdata[<span class="number">2</span>] = relativePosition.z / m_LocationNormalizationFactor;</span><br><span class="line">            otherAgentdata[<span class="number">3</span>] = info.TeamID == teamID ? <span class="number">0.0f</span> : <span class="number">1.0f</span>;</span><br><span class="line">            otherAgentdata[<span class="number">4</span>] = info.Agent.HasEnemyFlag ? <span class="number">1.0f</span> : <span class="number">0.0f</span>;</span><br><span class="line">            otherAgentdata[<span class="number">5</span>] = info.Agent.Stunned ? <span class="number">1.0f</span> : <span class="number">0.0f</span>;</span><br><span class="line">            <span class="keyword">var</span> relativeVelocity = transform.InverseTransformDirection(info.Agent.AgentRb.velocity);</span><br><span class="line">            otherAgentdata[<span class="number">6</span>] = relativeVelocity.x / <span class="number">30.0f</span>;</span><br><span class="line">            otherAgentdata[<span class="number">7</span>] = relativeVelocity.z / <span class="number">30.0f</span>;</span><br><span class="line">            <span class="keyword">return</span> otherAgentdata;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>观察空间输入</p><table><thead><tr><th>观察空间编号</th><th>类型</th><th>描述</th><th>备注</th></tr></thead><tbody><tr><td>0</td><td>bool</td><td>当前是否可以射击</td><td></td></tr><tr><td>1</td><td>bool</td><td>是否眩晕</td><td></td></tr><tr><td>2-6</td><td>float</td><td>当前持有弹匣数，OneHot编码</td><td></td></tr><tr><td>7</td><td>float</td><td>当前血量&#x2F;总血量</td><td></td></tr><tr><td>8</td><td>float</td><td>前向向速度分量</td><td></td></tr><tr><td>9</td><td>float</td><td>横向速度分量</td><td></td></tr><tr><td>10-12</td><td>vector3</td><td>相对初始位置offset</td><td>将y轴数据移除</td></tr><tr><td>13</td><td>bool</td><td>冲刺CD，1为可以使用</td><td></td></tr><tr><td>16</td><td>bool</td><td>冗余位，当前输入始终为0</td><td>删除</td></tr><tr><td>17</td><td>float</td><td>剩余敌人数量比例</td><td></td></tr><tr><td>18~19</td><td>vector2</td><td>冗余位，输入0，0</td><td>删除</td></tr></tbody></table><p>后面优化后将观察空间缩小至16位</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;训练环境搭建&quot;&gt;&lt;a href=&quot;#训练环境搭建&quot; class=&quot;headerlink&quot; title=&quot;训练环境搭建&quot;&gt;&lt;/a&gt;训练环境搭建&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Version information:&lt;br&gt;ml-agents: 0.30.0</summary>
      
    
    
    
    <category term="Code" scheme="http://holmodi.fun/categories/Code/"/>
    
    
    <category term="强化学习" scheme="http://holmodi.fun/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="学习笔记" scheme="http://holmodi.fun/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Mark Down显示测试-诗歌搬运</title>
    <link href="http://holmodi.fun/posts/b61e059f.html"/>
    <id>http://holmodi.fun/posts/b61e059f.html</id>
    <published>2023-05-29T05:47:06.000Z</published>
    <updated>2023-05-29T06:07:31.092Z</updated>
    
    <content type="html"><![CDATA[<h1 id="冥想-穆旦"><a href="#冥想-穆旦" class="headerlink" title="冥想 -穆旦"></a>冥想 -穆旦</h1><blockquote><p>为什么万物之灵的我们，</p><p>遭遇还比不上一棵小树？</p><p>今天你摇摇它，优越地微笑，</p><p>明天就化为根下的泥土。</p><p>为什么由手写出的这些字，</p><p>竟比这只手更长久，健壮？</p><p>它们会把腐烂的手抛开，</p><p>而默默生存在一张破纸上。</p><p>因此，我傲然生活了几十年，</p><p>仿佛曾做着万物的导演，</p><p>实则在它们长久的秩序下</p><p>我只当一会小小的演员。</p></blockquote><hr><blockquote><p>把生命的突泉捧在我手里，</p><p>我只觉得它来得新鲜，</p><p>是浓烈的酒，清新的泡沫，</p><p>注入我的奔波、劳作、冒险。</p><p>仿佛前人从未经临的园地</p><p>就要展现在我的面前。</p><p>但如今，突然面对着坟墓，</p><p>我冷眼向过去稍稍回顾，</p><p>只见它曲折灌溉的悲喜</p><p>都消失在一片亘古的荒漠，</p><p>这才知道我的全部努力</p><p>不过完成了普通的生活。</p></blockquote><hr><h1 id="你不是别人-—博尔赫斯"><a href="#你不是别人-—博尔赫斯" class="headerlink" title="你不是别人 —博尔赫斯"></a>你不是别人 —博尔赫斯</h1><blockquote><p>你怯懦地祈助的</p><p>别人的著作救不了你</p><p>你不是别人，此刻你正身处</p><p>自己的脚步编织起的迷宫的中心之地</p><p>耶稣或者苏格拉底</p><p>所经历的磨难救不了你</p><p>就连日暮时分在花园里圆寂的</p><p>佛法无边的悉达多也于你无益</p><p>你手写的文字，口出的言辞</p><p>都像尘埃一般一文不值</p><p>命运之神没有怜悯之心</p><p>上帝的长夜没有尽期</p><p>你的肉体只是时光，不停流逝的时光</p><p>你不过是每一个孤独的瞬息</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;冥想-穆旦&quot;&gt;&lt;a href=&quot;#冥想-穆旦&quot; class=&quot;headerlink&quot; title=&quot;冥想 -穆旦&quot;&gt;&lt;/a&gt;冥想 -穆旦&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;为什么万物之灵的我们，&lt;/p&gt;
&lt;p&gt;遭遇还比不上一棵小树？&lt;/p&gt;
&lt;p&gt;今天你摇摇</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>博客迁移建设中</title>
    <link href="http://holmodi.fun/posts/cfcd47cf.html"/>
    <id>http://holmodi.fun/posts/cfcd47cf.html</id>
    <published>2023-05-29T05:42:18.000Z</published>
    <updated>2023-05-29T05:54:22.636Z</updated>
    
    <content type="html"><![CDATA[<p>Hi, 这是我新建的个人博客，未来会选择之前的笔记，重新复习梳理，分享在个人博客里。近期会先放一些水填充内容测试博客各种功能。</p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Hi, 这是我新建的个人博客，未来会选择之前的笔记，重新复习梳理，分享在个人博客里。近期会先放一些水填充内容测试博客各种功能。&lt;/p&gt;
&lt;hr&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>旧文-读《游戏的人》</title>
    <link href="http://holmodi.fun/posts/f0a8c7f0.html"/>
    <id>http://holmodi.fun/posts/f0a8c7f0.html</id>
    <published>2023-05-29T05:27:22.000Z</published>
    <updated>2023-08-06T13:36:59.226Z</updated>
    
    <content type="html"><![CDATA[<h1 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h1><p>此书著于20世纪30年代，二战前夕。作者约翰·赫伊津哈（Johan Huizinga，1872-1945）是<br>荷兰历史学家、文化学家。他攻读印欧语——日耳曼语语言学，1897年获博士学位。先后在<br>荷兰和德国的莱顿大学、格罗宁根大学、莱比锡大学等著名大学执教，曾任莱顿大学校长；<br>他对游戏的兴趣可以追溯到1903年。那一年，他完成了东方学和梵文的学业（据其回忆录<br>《我踏上历史研究之路》描绘，他逐渐转向这个研究领域几乎是纯粹偶然的机遇）。1933<br>年，他发表作品《明天即将来临》，日益深化的政治危机使他感到压力。尽管如此，他研究<br>游戏的兴趣还是不曾动摇，1938年，发表《游戏的人》。二战期间，他对法西斯占领者持<br>严厉批判态度，1945年荷兰解放前夕被迫害致死。</p><h1 id="游戏的定义"><a href="#游戏的定义" class="headerlink" title="游戏的定义"></a>游戏的定义</h1><p>在书本的第一章，作者开篇明义，表达了自己对“游戏（英译“Play”，第二章提到类似汉语<br>中的“玩”“争”）”这一概念的理解，之后作者便开始了从抽象到具体的过程。正如文中所提<br>及：“在一些所谓原始的语言里，同一物种的不同纲目用了不同的词，它们用不同的单词表<br>达鳗鱼和梭子鱼，表达“鱼”的词反而没有。”作者在这本书里不断的列举游戏和神话、仪<br>式、法律、战争、诗歌、知识、哲学、各种艺术门类的关系，仿佛是在读者面前宣告了一个<br>目前语言中不存在的，作者把它称为“游戏”的总体概念之后，再在读者眼前展示一条条鳗<br>鱼、梭子鱼，通过各章节描述这几条实体的“鱼”与抽象的“鱼”的概念之间的联系后，最终在<br>读者面前阐明了一个具有非物质属性的“游戏”这一概念。<br>    作者在序言里首先提到了智人、工匠人、游戏人这三个概念，将游戏人和其余二者放在了同<br>样的地位上，首次阐明了游戏的重要性，又给出论断：“文明是在游戏之中成长的，是在游<br>戏之中展开的，文明就是游戏。”随后便提出，游戏比文明的历史更加悠久。在人类社会没<br>存在之前，游戏便已经存在于动物界，两只小狗互相玩耍便是游戏最简单的形式，游戏还有<br>更加高级的形式：竞赛(contest)和表演(representation&#x2F;display)。这两种功能可以结合起<br>来，使游戏再现一种竞赛，或成为某种最佳表征的一种竞赛。文化以游戏的形式出现，文化<br>从发轫之日起就是在游戏中展开的。同样，这两种形式也是走在文化之前的。从鸟类的舞蹈<br>竞技、互相展示羽毛，到主调合唱、翻绳游戏、古希腊的戏剧表演和辩论，再到赌博游戏、<br>奥林匹克运动，都可以归类为一种竞赛形式的高级的游戏形式。从孔雀展示自己羽毛的表<br>演，从儿童游戏过渡到古老神圣的表演，从野蛮人的神秘仪式到现代的宗教仪式，作者都将<br>其归类到表演的范畴，它们都是表现某种东西的形式，“原始或古老的仪式是神圣的游戏，<br>对社会的福祉不可或缺，能使人产生对宇宙的洞察力，能推动社会的发展，然而它总是游戏<br>”，用再现的方法来实现的游戏，仍然在各个方面保留着基本的形式特征。随后，作者一一</p><p>阐述，神话、仪式、法律、战争、诗歌、知识、艺术、哲学中都有游戏成分，或者说就是游戏。最终呼应了作者自己对游戏的具体定义：</p><p>“如果要总结游戏的形式特征，我们不妨称之为一种自由的活动，有意识脱离平常生活并使之“不严肃”，同时又使游戏人全身心投入、忘<br>乎所以的活动。游戏和物质利益没有直接的关系，游戏人不能从中获利。游戏在特定的时空<br>范围内展开，遵守固定的规则，井然有序。游戏促进社群的形成，游戏的社群往往笼罩着神<br>秘的气氛，游戏人往往要乔装打扮或戴上面具，以示自己有别于一般的世人。 ”在表述了各<br>种形式的游戏后，作者有给出了这样的论断：最重要的形式就是游戏本身。这样的游戏就具<br>有游戏的全部特征：秩序、紧张、运动、变化、庄严、节律、狂喜。只有到了稍后的社会阶<br>段，游戏才和表达什么东西的观念联系起来，才和所谓“生命”或“自然”的观念产生联系。在<br>游戏的形式和功能里，人嵌入神圣的万物秩序里的自我意识，得到了最初的、最高级的、最<br>神圣的表达，而游戏本身是独立的实体，是无意识和非理性的。仪式嫁接到了游戏之上，但<br>首要的东西是游戏而不是仪式，始终都是游戏。这就是说，游戏的行为自始至终自足于自<br>身，其结果不必对群体的生活进程做出贡献。重要的不是弹子，而是玩弹子的游戏过程。游<br>戏是一种特殊的活动，一种“意义隽永的形式”，一种社会功能——这才是我们研究的主题。<br>我们将研究游戏这种社会构造成分的诸多具体的形式。从一开始，人类社会宏大的原型活动<br>就充满了游戏。真正而纯粹的游戏是人类文明的基础之一。</p><h1 id="游戏的特征"><a href="#游戏的特征" class="headerlink" title="游戏的特征"></a>游戏的特征</h1><h2 id="一-游戏是自愿的"><a href="#一-游戏是自愿的" class="headerlink" title="一 游戏是自愿的"></a>一 游戏是自愿的</h2><p>对于成人和有责任心的人而言，游戏这个功能同样是可以抛弃的。游戏也可能是多余的。只<br>有在游戏的乐趣成为紧迫的需要时，我们才需要游戏。游戏是任何时候都可以推迟或暂停<br>的。游戏绝不是身体之必需或道德之责任强加于人的。游戏从来就不是什么任务。游戏是在<br>休闲中进行的，是在“空余时间”进行的。只有当游戏被认为是文化功能比如仪式或典礼时，<br>游戏才和义务、责任之类的观念联系在一起。单凭这一点自愿的特征，游戏就和自然界其他<br>的机制划清了界限。</p><h2 id="二-游戏并非“平常的”或“真实的”生活，它步出了“真实的”生活，进入一个暂时的活动领域"><a href="#二-游戏并非“平常的”或“真实的”生活，它步出了“真实的”生活，进入一个暂时的活动领域" class="headerlink" title="二 游戏并非“平常的”或“真实的”生活，它步出了“真实的”生活，进入一个暂时的活动领域"></a>二 游戏并非“平常的”或“真实的”生活，它步出了“真实的”生活，进入一个暂时的活动领域</h2><p>真正的游戏至少还有一个基本的特征：自觉意识。无论这样的自觉意识隐藏得多么深，“仅<br>仅是在假装”的自觉意识始终是存在的。游戏具有的这个“假装”的特征指明，人内心存在着<br>游戏意识，和“严肃”相比较而存在，这种“假装”的意识似乎和游戏一样是第一位的意识。</p><h2 id="三-其隔离性与局限性"><a href="#三-其隔离性与局限性" class="headerlink" title="三 其隔离性与局限性"></a>三 其隔离性与局限性</h2><p>游戏和现实利益没有直接的关系。</p><p>时间的局限性：游戏有一个起点，到了某一时刻，它又“戛然止步”，一旦玩过之后，这个游<br>戏就作为一种创新的心灵形式保存下来，就成为记忆中的珍藏。在游戏的一切高级形式中，<br>重复和交替的成分（比如诗歌中的叠句和音乐中的副歌）就像纺织品的经纱和纬线。这个重<br>复的机制里蕴藏着最重要的游戏属性，这个重复机制不仅适用于游戏的总体形式，而且适用<br>于游戏的内部结构。<br>空间的局限性：神圣的场地”和游戏的场地也没有明确而显著的区别。一种绝对而独特的秩<br>序居主导地位。游戏创造秩序，游戏就是秩序。游戏具有最崇高的属性，我们能从事物中感<br>受到的属性：节律与和谐。游戏最重要的特征之一是它在空间上与平常生活的脱离<br>其他特征：<br>紧张和不确定性：游戏的竞赛性越是强烈，投入游戏的热情就越是高涨 。<br>对欺骗者的宽容大大超过了对搅局者的宽容。退出游戏之后，他揭示了这个游戏世界的相对<br>性和脆弱性，他只是短暂地隐藏到游戏人的队伍中。他使游戏里的幻觉（illusion）荡然无<br>存<br>游戏喜欢把自己笼罩在神秘的气氛之中，游戏的“独特”和秘密最生动地体现在“化装”之中。</p><h1 id="游戏的乐趣（fun）"><a href="#游戏的乐趣（fun）" class="headerlink" title="游戏的乐趣（fun）"></a>游戏的乐趣（fun）</h1><p>第一章作者便指出，即使在最简单的动物层次上，游戏也不只是纯粹的生理现象和心理反<br>射。它超越了单纯的生理活动和心理活动的范畴。它有一个意义隽永的功能，也就是说它具<br>有特定的意义。在游戏时，有一种东西在起作用，它超越了生活的眼前需要，它给行为注入<br>了特定的意义。一切的游戏都具有特定的意义。倘若我们把构成游戏本质的积极原理叫作<br>“本能”，我们并没有做出任何解释；倘若我们称之为“心灵”（mind）或“意志”（will），我<br>们的解释又太过头。无论我们怎么看待游戏，游戏都具有特定的意义，这个事实隐含着游戏<br>本身的非物质属性。我们可以将这一非物质属性称为游戏的乐趣（fun）。作者指出，乐趣<br>是不能分析的，一切逻辑的解释都无能为力。正是乐趣这个成分构成游戏的本质特征。“在<br>解释原始游戏时，我们立即遭遇到不可简约的纯游戏乐趣”。这个特征有一个顽强的抵抗<br>力，一切想把游戏简约为其他字眼的努力都是徒劳无益的。<br>不过，即使语言和理性无法详细表述乐趣，它的存在却是每一个人都可以感受的到的。一款<br>电子游戏是否“好玩”，一次活动是否“精彩”，一部电影是否“好看”，每一个亲历者都能立刻<br>给出答案，都可以感受到其中是否存在“乐趣”，即使难以表述出究竟是哪一部分让人觉得<br>“有趣”。《心流》书中同样描述过在心流状态时人能体验到一种深刻的愉悦感，而这种愉悦<br>感或许构成了游戏乐趣的一部分。<br>因此，正如智人拥有理性，工具人具有使用工具的能力，游戏人或许也具有感受这种乐趣的<br>能力，从一只鸟到一个人，都能从游戏中感受到纯粹的乐趣。而这种乐趣或许就是驱使人去<br>游戏的原因。</p><h1 id="游戏与严肃"><a href="#游戏与严肃" class="headerlink" title="游戏与严肃"></a>游戏与严肃</h1><p>书中多次探讨游戏与严肃之间的关系，第一章便指出，游戏与严肃不是对立的，游戏也置身<br>于愚蠢和智慧的对立之外，也超越真理和谬误、善与恶的对立。游戏是一种非物质的活动，<br>但它并没有道德的功能。随后又提及，游戏和严肃的差别是变动不羁的。游戏转变成严肃，<br>严肃又可以转变成游戏。游戏可能会上升到美和崇高的境界，甚至远远高居于严肃之上。文<br>明逐渐产生了两种精神生活的分野，分别称之为游戏和严肃。起初，游戏和严肃构成浑然一<br>体的精神生活中介，文明就是从这种不可分割的精神生活中产生的。<br>作者在文中多次感叹游戏精神的衰落，游戏不断的转向严肃。在文明演进的过程中，竞赛功<br>能在古典时代获得了最美的形式，成为最引人注目的要素。文明发展的趋势是越来越复杂多<br>样，越来越层层叠压，生产技术和社会生活的技术在组织上越来越精致。在这个过程中，古<br>老的文化土壤在重重叠叠的重压下越来越难以呼吸，思想和知识体系、教义、规章制度、道<br>德和常规习俗都失去了和游戏的联系。于是我们说，文明变严肃了，它只给游戏指派一个次<br>要的位置。英雄时代一去而不复返。随后，在当代文明中的游戏成分章节中，作者感慨：<br>18世纪以来，文化里的游戏成分一直在衰减。今日之文明再也不玩游戏了，即使表面上玩<br>游戏的地方，那也是虚假的游戏。作者称古代战争始终被认为是高尚的游戏即君王的游戏；<br>战争规则的绝对约束性建立在一些游戏的形态成分上，而且始终保留着这些游戏的形态成<br>分。然而在当代，战争却远远超过了纯粹野蛮的竞争，不仅古老游戏精神的最后遗存会荡然<br>无存，而且任何文明的主张也会消失殆尽。到那时，社会就会堕落到野蛮的底层，原始的暴<br>力又将死灰复燃了。至此，作者给出结论:在游戏成分或缺的情况下，真正的文明是不可能<br>存在的；这是因为文明的预设条件是对自我的限制和控制，文明不能将自己的倾向和终极目<br>标混为一谈，而是要意识到，文明是圈定在自愿接受的特定范围之内的。在一定的意义上，<br>文明总是要遵守特定游戏规则的，真正的文明总是需要公平的游戏。公平游戏就是游戏条件<br>中表达出来的坚定信念，所以游戏中的欺诈者和搅局人粉碎的是文明本身。要成为健全的文<br>化创新力量，这个游戏成分必须是纯洁的。如果理性、信念或人道建立起来的标准被抹黑、<br>被亵渎，这个游戏成分就不可能存在。这个游戏成分不应该是虚假的外表，我们不应该让虚<br>假的面具把政治目的隐藏在虚幻游戏形式背后。真正的游戏和宣传没有关系，游戏的目的就<br>是游戏，它那广为人知的精神激励人、使人愉快。<br>“什么是游戏？”“什么是严肃？”这两个问题和我们捉迷藏并迷惑我们，直到本书的结尾。每<br>当思考这两个问题时，我们将发现那个固定不动的终极之点，这是逻辑无法达到的伦理领域<br>的终极之点。作者以这段话结束全书，将游戏与严肃的思考抛给后人。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;作者简介&quot;&gt;&lt;a href=&quot;#作者简介&quot; class=&quot;headerlink&quot; title=&quot;作者简介&quot;&gt;&lt;/a&gt;作者简介&lt;/h1&gt;&lt;p&gt;此书著于20世纪30年代，二战前夕。作者约翰·赫伊津哈（Johan Huizinga，1872-1945）是&lt;br&gt;荷兰历史</summary>
      
    
    
    
    <category term="Games" scheme="http://holmodi.fun/categories/Games/"/>
    
    
    <category term="游戏" scheme="http://holmodi.fun/tags/%E6%B8%B8%E6%88%8F/"/>
    
  </entry>
  
  <entry>
    <title>旧文-读Chris Crawford谈互动叙事</title>
    <link href="http://holmodi.fun/posts/5ffa11e3.html"/>
    <id>http://holmodi.fun/posts/5ffa11e3.html</id>
    <published>2023-05-29T05:22:45.000Z</published>
    <updated>2023-08-06T13:43:30.628Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是互动叙事"><a href="#什么是互动叙事" class="headerlink" title="什么是互动叙事"></a>什么是互动叙事</h2><p>Chris Crawford在序章中指出，当电子游戏最终走向成熟从而演化为一种艺术表达的媒体时，它必须是关乎“人本”的，而不是关乎物件的。而大部分电子游戏仍然以“物件（things）”为中心，我们追赶、消灭、搜寻、移动的都是它，而未与其他人物发生过多戏剧性的交互，这是互动叙事需要解决的核心问题。</p><p>互动叙事的基础是“<strong>交互</strong>”+“<strong>故事叙述</strong>”。而交互性的概念被定义为：“发生在两个或多个主体（active agent）之间的循环过程，各方在此过程中交替地倾听、思考和发言，形成某种形式的对话”，这种交互必须是双向的。因此，电影这种艺术作品虽然能唤起观众反应却不是“交互式”的艺术作品，观众没有实施主动动作，不能影响电影剧情走向。</p><p>书中第四章结尾给出了一个互动叙事的“过程”实例：</p><blockquote><p>爷爷给小女孩将故事，小女孩对小马驹的细节感兴趣，爷爷便丰富马驹的细节，小女孩向知道小马是否去了山上，爷爷便丰富小马去山上的过程，小女孩不喜欢小马在山上跳来跳去，爷爷又略微修改了故事·····</p></blockquote><p>第五章又指出了用动词的思考方式，指出如果需要实现交互就需要这种思考模式。</p><p><strong>综上可以这样概括互动叙事系统：</strong>需要这个系统需要拥有理解玩家潜在可能输入的大量“动词”的能力，玩家在思考并选择了某一动词作为自己的行动后，系统有能力在这些动词的基础上输出合乎人类基本逻辑又蕴含极多变数的“动词”，并依据上下文继续讲述故事。玩家在这一系列的动词输入中，体验到了一个完全基于自己的选择生成的，独一无二的故事。互动叙事系统是完全由玩家驱动的故事叙述系统。</p><h4 id="《西部世界》–互动叙事的极致模板"><a href="#《西部世界》–互动叙事的极致模板" class="headerlink" title="《西部世界》–互动叙事的极致模板"></a>《西部世界》–互动叙事的极致模板</h4><p>美剧《西部世界》的设定极为符合Chris Crawford的互动叙事模型。</p><blockquote><p>故事设定在未来世界，在一个庞大的高科技成人主题乐园中，有着拟真人的机器“接待员”能让游客享尽情欲、暴力等欲望的放纵，主要叙述被称为“西部世界”的未来主题公园。</p></blockquote><p>剧中的甜水镇有着数十个性格角色鲜明的人物在此生活，即使没有真人进入，这个镇子的一天也会正常运转，暗藏多条故事线，而第二天所有的机器人都会被重置，重复第一天发生的故事。而当游客进入这个公园后，便可以与其中的人物发生各种互动，而这些互动往往会产生蝴蝶效应，从而影响整个镇子的故事发展。剧中的主角曾多次进入乐园，而每一次进入时和他共同进入的游客以及他自己对这个乐园的经验都完全不同，因而导致在每次体验时即使机器人在新的一天会被重置成完全相同的状态，但每天发生的大部分交互都不一样，流程中发生的故事完全不同。</p><p>玩家能选择的潜在的“动作”的数量等同甚至超过现实世界的潜在“动作”，因而创造了极强的交互性，也因这些潜在的交互动作而增强了玩家的体验。如果一个玩家潜在的不能选择一些罪恶的“动作”选项，又怎能因为选择了正义的选项来证明自己在做一个正义的西部牛仔的荣誉感呢？如果说互动叙事中的体验核心在于选择，那么选择不做哪些潜在的动作同样是一种体验，总有玩家会在GTA里等红绿灯，不能因为是GTA设计师就不会在马路上设置红绿灯。</p><p>而这个游乐园的故事的生成来自于两个部分，固定的故事线以及玩家和机器“接待员”以及“接待员”之间的交互。玩家可以依照正常的故事线游玩，发现每个角色背后的秘密，也可以做出超出设计师想象的动作。剧中有这样一幕：由于接待员的人工智能过于强大，在玩家的帮助下发现了自己的真实身份，觉醒自我意志，跑到游乐园的另一个位置：日本幕府时代的场景中，但这帮牛仔仍然能与那个世界观设定下的接待员正常的进行交互并相互理解合作，从而发生一系列故事。</p><h2 id="什么不是互动叙事"><a href="#什么不是互动叙事" class="headerlink" title="什么不是互动叙事"></a>什么不是互动叙事</h2><p>依照Chris的理论，很容易界定出哪些不是互动叙事。首先，电影等传统艺术这种只能让用户反应而不是交互的都不是互动叙事。其次，大部分的电子游戏也远远不符合互动叙事的概念。Chris在书中也指出了现在电子游戏的一些问题，而这些可能也是导致玩家体验较差的因素：</p><h4 id="基于分枝树的剧情结构"><a href="#基于分枝树的剧情结构" class="headerlink" title="基于分枝树的剧情结构"></a>基于分枝树的剧情结构</h4><p>虽然分支树的故事结构能给玩家提供一种掌控感，Chris对此的评价为“对于困在沙漠中快渴死的人来说这几滴水无济于事”。大部分游戏的分支结构如果想做的庞大都会面临着指数爆炸的风险，设计师不可能让玩家的每一个选择都有意义，否则制作这颗分枝树的工作量将远远超出团队能力的极限。因此，在游玩过程中很多选项其实是虚假的，选择对剧情没有任何影响，整个游戏的剧情分支甚至用一张图就能概括，这样的分支树结构远远不能够达成互动叙事的目标，而且当玩家发现自己的行为无法真正意义上的影响剧情走向甚至对剧情发展完全无影响时会产生极大的挫败感。</p><h4 id="开放世界"><a href="#开放世界" class="headerlink" title="开放世界"></a>开放世界</h4><p>玩家在开放世界中探索，进行着各种主线或支线任务，游玩各种小游戏，一旦触发了某些关键节点，剧情就会继续推进。Chris将开放世界定义为将传统故事附加到游戏当中的一种做法，即把传统的故事拆分为碎片，散落到游戏当中，由玩家收集碎片并重新拼装成完整的故事。个人理解的开放世界和非结构化叙事有着千丝万缕的联系，而这种手法更像是一种拼图游戏：根据自己整理的碎片以及相关线索，去搜集剩余的拼图，直到把它们拼成一个完整的图案，因此乐趣的来源不仅是这张拼图图案的美感，更来自于拼装的过程。开放世界的故事就像是把一本完整的书撕成几份并打乱，在读完后从一个无序的结构中理出一个合理的顺序出来。</p><p>这种传统叙事手法和开放世界玩法总会有冲突的时候：《巫师3》的杰洛特总是被玩家玩成一个沉迷打昆特牌，偶尔想起才去救女儿的懒人，《荒野之息》的林克总被玩成一个除了拯救公主什么事情都干的海拉鲁流氓，而在剧情中他们的人设显然不是这样的。而另一个问题是为了填充开放世界地图场景里出现很多近乎凑数的调查点，导致传统叙事流程的故事和玩家的自由探索</p><p>开放世界游戏又陷入了播放一段动画，玩家继续玩自己的游戏，然后触发事件，体验一段预设好的和之前的玩家行为造成后果关联不大的主线剧情的尴尬场景。</p><h4 id="简陋的NPC交互"><a href="#简陋的NPC交互" class="headerlink" title="简陋的NPC交互"></a>简陋的NPC交互</h4><p>有玩家录制上传过声势浩大的《赛博朋克2077》中的这样一幕：玩家在人潮汹涌的市中心丢一颗炸弹，瞬间条马路上各种身份和穿着的路人都同时以一个相同的姿势从车中出来，双手抱头，持续几秒后又同步上车，面无表情的开走车辆。</p><p>大部分时候游戏里的NPC无论在游戏里担任什么身份或职位，只要一离开过场剧情动画阶段，都扮演一个很傻很呆的角色，重复着几句无聊的对话，被玩家以奇怪的操作推开后还会呆呆的自动寻路走回自己的位置，或者扮演一个谜语人说一些玩家听不懂的话。使用Chris的说法就是这些NPC仅仅是游戏里的“物件”，完全没有能力扮演一个真正的NP“Character”，但从另一方面考虑，如果需要一个游戏角色能够完成Chris所设想的那种交互，那么某种程度上他也是一个能够通过图灵测试的人工智能，这时候限制互动叙事引擎的是科技技术水平而不是设计层面的问题。</p><h2 id="“涌现”式设计与互动叙事"><a href="#“涌现”式设计与互动叙事" class="headerlink" title="“涌现”式设计与互动叙事"></a>“涌现”式设计与互动叙事</h2><p>游戏系统中的各个机制之间联系密切，自然会产生很多有趣的交互体验：</p><p>​有一段著名的矮人要塞猫为何离奇死亡的故事：</p><blockquote><p>矮人们在酒馆中打架，把酒杯摔在地上，地面上到处都溅着酒精，当猫大摇大摆经过的时候，浑身上下就沾满了酒！而游戏中酒精中毒的特性与身材大小相关，当猫给自己舔毛清理，理论上相当于喝下了几大杯的啤酒，理所当然，它们酒精中毒了。</p></blockquote><p> 这个小片段的发展完全不在设计者和玩家的预料之中，却又合乎情理。游戏中的各个机制复杂而具有一定深度，又能够正确的相互交互，即使这些系统间的相互交互没有发生在用户界面，以至于能够实现设计师无法预料的事情，使得游戏成为一个故事叙述引擎，自己能够根据上下文来生成故事。这类游戏中，动作抉择产生的故事性往往是依靠这次选择的上下文来赋予的，在《Rim World》的世界里，玩家第一次迫降砍伐树木的体验，和面临基地被摧毁缺乏时发现一颗树并砍伐的心情是不一样的，就像书中提及的依靠上下文语境给吃豆人玩家大量不同的考量。</p><p>然而矮人要塞这类游戏仅有简陋的交互界面，大部分状态表现为一串数据，玩家能进行的动作也是有限的，如果想让玩家能有大量可选择的动作，同时又要满足每个动作都能参与到整个系统的交互中，整个系统的复杂性可能也超过了当今技术水平。</p><h2 id="对互动叙事概念的质疑点"><a href="#对互动叙事概念的质疑点" class="headerlink" title="对互动叙事概念的质疑点"></a>对互动叙事概念的质疑点</h2><h3 id="规则的边界"><a href="#规则的边界" class="headerlink" title="规则的边界"></a>规则的边界</h3><p>Chris在书中使用决定论与自由意志的冲突来说明游戏中玩家的自由度和设计师对故事剧情的发展掌控要如何调和，而这种冲突在他的互动叙事概念下却是不可调和的，电子游戏这种媒体天然的需要玩家服从一定的规则，必须对玩家的行为有一定的限定，而互动叙事却又需要玩家能做出的动作相当自由，那必然会存在玩家想要做但被系统规则限制的“动作”，这时候玩家会不会质疑自己玩的到底是不是真正意义上的互动叙事？互动叙事真的能够如他所设想的那样完全脱离游戏成为一个独立的概念吗？想要接近这个目标就要无限的扩充规则的边界，直到无限接近甚至超过现实世界的互动机制才会让玩家发觉自己设想的所以动作都能在这个引擎里完整的实施出来，但想完美的复制现实的各类规则过于困难，也是以现在的计算机技术难以实现的。</p><h3 id="用户真的需要互动叙事吗"><a href="#用户真的需要互动叙事吗" class="headerlink" title="用户真的需要互动叙事吗"></a>用户真的需要互动叙事吗</h3><p>Chris多次在书中提及自己的第一原则：永远以用户为中心进行设计。然而用户真的需要互动叙事吗？如果用户是为了体验一个触动情感的故事，为什么互动叙事生成的故事就一定会比一位老练的作家精心设计的结构要更独特呢？是否每一位玩家都具有能力在一个完全由玩家的行为驱动引擎中做出相对正确的选项以保证整个故事的体验能维持在较高的水准，如果一个玩家面对这个情景无所适从怎么办？一个自由度过高的互动叙事故事的发展过于依赖玩家的游戏水平。</p><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>虽然Chris尝试搭建的互动叙事系统Storytron在市场和预期结果上失败了，但他留下的话却鼓舞人心：</p><p>  It has been said that the only people who create progress are those crazy enough to refuse to adapt to reality. I was certainly that crazy, but eventually reality won. I put up a damn good fight, but I lost the second round. Now I’m going into the third round, and recognizing my own frailty I’m planning it more carefully, proceeding more slowly. <strong>This is my life’s work, and I’m not dead yet.</strong></p><p>Chris对互动叙事的未来充满希望，或许这位游戏大师的互动叙事系统代表着未来游戏模式的雏形。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是互动叙事&quot;&gt;&lt;a href=&quot;#什么是互动叙事&quot; class=&quot;headerlink&quot; title=&quot;什么是互动叙事&quot;&gt;&lt;/a&gt;什么是互动叙事&lt;/h2&gt;&lt;p&gt;Chris Crawford在序章中指出，当电子游戏最终走向成熟从而演化为一种艺术表达的媒体时，它必</summary>
      
    
    
    
    <category term="Games" scheme="http://holmodi.fun/categories/Games/"/>
    
    
    <category term="互动叙事" scheme="http://holmodi.fun/tags/%E4%BA%92%E5%8A%A8%E5%8F%99%E4%BA%8B/"/>
    
    <category term="游戏" scheme="http://holmodi.fun/tags/%E6%B8%B8%E6%88%8F/"/>
    
  </entry>
  
  <entry>
    <title>电影文本创作课程笔记</title>
    <link href="http://holmodi.fun/posts/3d449bcf.html"/>
    <id>http://holmodi.fun/posts/3d449bcf.html</id>
    <published>2023-05-20T14:50:26.000Z</published>
    <updated>2023-05-29T05:41:04.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="共情"><a href="#共情" class="headerlink" title="共情"></a>共情</h1><p>目录<br>确立影像化思维<br>重点概念：场景<br>电影文本长什么样<br>故事的道德前提<br>用结构来讲故事<br>拿事儿说话<br>人物怎么写<br>  人设 人物小传 人物塑造<br>   对白的八大风格八项注意</p><hr><p>艺术创作都有基础格律<br>电影分类：三分法 </p><p>· 类型片（标准化工业化的产品）<br>  致力于寻找大众的体验审美情感的公约数<br>  困境是人设计出来的，最后会被解决<br>· 文艺片  中间状态的<br>· 艺术电影  和类型片完全相对的，反模式反格式化反规律的。呈现讨论困境，不会解决困境</p><p>影像化叙事，视听语言，视听语言有六个变量<br>分场戏</p><hr><h1 id="影像化思维"><a href="#影像化思维" class="headerlink" title="影像化思维"></a>影像化思维</h1><p> 电影的单位叫场<br> 剧本是导向制作的“蓝图”，好的电影局本天生是带着影像的</p><p>  用影像的和视听的思维写作，不能脱离电影本体，才能写出有镜头感的文字</p><p>  视听语言的要素：景别（远全中近特）交替使用景别会让画面更生动富有节奏感、角度、焦距、光线、色彩、运动、声音+时间和空间。</p><p>  ·由画面讲述出来的故事<br>  ·通过画面、对话、动作来讲述故事，并把这个故事放置在一个戏剧性情境中</p><p> <strong>核心：蒙太奇</strong>：剪辑构成组接，电影创作的基本方式，包括前期的构思，体现在镜头和镜头之间，线索和线索之间。可以分切和重组时空，将不同时刻拍的素材统一成一个被电影再造出的时空。<br>  平行蒙太奇：不同时空发生的两条或两条以上的 情节线索分头展开，并列表现。<br>  交叉蒙太奇：<strong>同一时间不同地点</strong>发生的两条或数条情节迅速而频繁地交替剪接在一起，其中一条线索的发展往往影响另一条线索，各条线索相互依存最后汇合在一起。<br>  对比蒙太奇：在内容或形式方面形成对比。<br>  心理蒙太奇：人物心理的造型表现。<br>  隐喻蒙太奇：f</p><hr><h1 id="项目提案"><a href="#项目提案" class="headerlink" title="项目提案"></a>项目提案</h1><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h2><p>   标题<br>   一句话故事<br>   标签墙<br>   人物小传<br>   梗概<br>    让人想看 让人想买，内容扎实，文字高度简练<br>   八要素<br>     1 人物：身份 欲望 动作<br>        身份 正向人物含有负价值的定语<br>        欲望 朴素原始<br>        动作 及物<br>     2 事件：问题 阻力 结果 ：故事主线 基本情节 主要矛盾冲突<br>     3 主题：正价值 负价值<br>     其他：创意点 与当下话题的关联度 运行可行性<br>   样场</p><h1 id="电影文学剧本"><a href="#电影文学剧本" class="headerlink" title="电影文学剧本"></a>电影文学剧本</h1><p> 场 序列 转场 过场戏<br>  具备文学要素，符合文学特性，追求文学深度，遵循写作文法<br>  电影化的文学。文体特征由电影的特性所决定。荧幕意识视听思维镜头感三维空间意识</p><h2 id="剧本格式"><a href="#剧本格式" class="headerlink" title="剧本格式"></a>剧本格式</h2><p>   场景条<br>     场景号 内景&#x2F;外景 地点 夜景&#x2F;日景<br>     1. 外 街道 日<br>  台词冒号后不加引号</p><p> <strong>上课用格式要点</strong><br>   环境描述和行动描述前面加三角，人物对白不加<br>   空间变了要分场，要有先场景时的空间意识</p><h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><p>时间和空间</p><p>  场景即命运，场景要和人物有机的关联在一起，场景是空间概念同时也是时间概念，同一个空间不连续的时间也要分场 。</p><h2 id="场景的作用"><a href="#场景的作用" class="headerlink" title="场景的作用"></a>场景的作用</h2><p>   传达信息（环境动作对白）<br>    推动情节（转折、变化）<br>    传递影片氛围、质感<br>    揭示人物（性格 趣味习惯内心状态的外延外化）<br>    表达主题</p><p>1.从场景入手来构思剧情，利用场景中的要素来表现人物（年代感社会生活地域），让寻常的场景变得不寻常（一个人从银行跑出来）。打破场景直线，让场景带上节奏。场景不能过于单一和集中，需要多变一些</p><p>2.分场戏的容量要有大有小，主戏或者过场戏要有分别，通过时空的交错和不同线索的交织并进来打破场景的呆滞感，有节奏和错落感。让一个序列内的场景呈现阶梯序列的结构。时空的交错穿插。</p><p>3.动进动出。从动作中进戏，从动作中出戏。保持戏的势能，把握节奏，不要赘述太多冗余的细节，不要太多状态。把名词形容词改成动词。eg:老大捡鸡蛋</p><p>4.潜文本与文本：<br>    文本只表达出潜文本的一部分<br>    文本和潜文本看似无关<br>    文本和潜文本相反<br>    潜台词和台词<br>     eg.四太太和丫鬟<br>     打麻将 色戒  罗曼蒂克消亡史</p><hr><h1 id="电影文本的基本特征"><a href="#电影文本的基本特征" class="headerlink" title="电影文本的基本特征"></a>电影文本的基本特征</h1><p> 跳跃性 （非线性） eg 暗杀 找人</p><p> 可视性 （形象直观性）<br>   用文字去给出一连串的视听形象，不要去堆砌美丽的文字语言，只写摄影机能拍下来的和演员能表演的情节。用外在的事件动作来展示人物内心的变化。</p><p> 动作戏<br>  有效的体现人物内心活动的动作。在作品规定的情境中，能推动。<br> 简约性<br>  尽可能写短句，删除连词，保留能够清晰表达视听形象的名词动词，意思雷同的句子合并处理，去掉可有可无的套话。</p><hr><h1 id="规定情境"><a href="#规定情境" class="headerlink" title="规定情境"></a>规定情境</h1><p> 人物面临的各种情境的总称。包括：<br>  特定的时空环境（自然，时代和社会）<br>  对人物发生影响的事件及情势<br>  人物关系<br>分镜头本</p><hr><p>正能量战胜负能量<br>价值观是最低也是最高</p><h1 id="用结构来讲故事"><a href="#用结构来讲故事" class="headerlink" title="用结构来讲故事"></a>用结构来讲故事</h1><ul><li>结构：一部影片的布局，讲故事的顺序，情节线索的排列组合，各部分轻重比列及相互之间的关系</li></ul><h2 id="救猫咪：金羊毛-伙伴之情-超级英雄-鬼屋-侦探推理-麻烦家伙-变迁仪式-如愿以偿-愚者成功-被制度化"><a href="#救猫咪：金羊毛-伙伴之情-超级英雄-鬼屋-侦探推理-麻烦家伙-变迁仪式-如愿以偿-愚者成功-被制度化" class="headerlink" title=" 救猫咪：金羊毛 伙伴之情 超级英雄 鬼屋 侦探推理 麻烦家伙 变迁仪式 如愿以偿  愚者成功 被制度化  "></a> 救猫咪：金羊毛 伙伴之情 超级英雄 鬼屋 侦探推理 麻烦家伙 变迁仪式 如愿以偿  愚者成功 被制度化  </h2><p>故事是按时间序列发生的事件，情节是根据特定的叙事目的和特定的逻辑组织起来的事件</p><p>情节点<br> 大情节点 小情节点<br> 主要 次要 过渡性 表现性</p><p>钩子：激励事件&#x2F;干扰事件<br> 钩子有没有对主人公的命运起到足够的 干扰，让他有必要行动起来<br> 反常突发、两难选择、小人物摊上大事，大人物摊上小事</p><p>情节点1（第一幕&#x2F;二 转折点）<br>故事真正开始的地方，主线情节的激发点，人物改变</p><p>情节点2（第二&#x2F;三幕转折点）<br>发现与急转的关键时刻，故事项新的方向发展，形成整部电影最紧张的时刻，走向高潮阶段</p><hr><p>  ·线性结构<br> · 非线性结构<br>     倒叙 插叙 折叠式叙事 时空交错<br> ·戏剧式结构<br> ·小说式结构<br> ·散文结构<br> ·戏中戏结构 《法国中尉的女人》<br> ·板块式结构源代码<br> ·多线交错式<br> ·时空交错<br> ·三幕式结构</p><ul><li>第一幕 建置部分<ul><li>主要人物出场</li><li>给出人物关系</li><li>创建规定情境</li><li>出现干扰事件、情境激化</li></ul></li><li>第二幕  发展部分<ul><li>发展冲突</li><li>深化冲突</li><li>抑制、拖延、突转</li></ul></li><li>第三幕 结局部分<br>- 冲突化解<br>- 凸显主题</li></ul><p><img src="https://image-1318257942.cos.ap-beijing.myqcloud.com/Pic/20230517181659.png" alt="image.png"><br>    - 开场：布局建置整个故事。<br>        -  尽快抓住观众的注意力<br>        - 使整个故事得以引发运转<br>        铺垫现状（我不是药神，鱿鱼游戏），构建世界（寄生虫，肖申克），树立人物（末日狂花）<br>        - 创作方法之一：晚入早出 故事尽可能晚的时刻开始讲起<br>        - 创作方法之二：迅速将观众带入规定情境<br>            - 特定的时空环境（自然，社会）<br>            - 对人物发生影响的事件及情势<br>            - 人物关系<br>            - <a href="https://movie.douban.com/subject/27668250/">南方车站的聚会 (豆瓣) (douban.com)</a>，<a href="https://movie.douban.com/subject/1291869/">本能 (豆瓣) (douban.com)</a><br>        - 创作方法四：人物<br>            - <a href="https://movie.douban.com/subject/1482072/">穿普拉达的女王 (豆瓣) (douban.com)</a><br>            - <a href="https://movie.douban.com/subject/1292062/">美国丽人 (豆瓣) (douban.com)</a><br>            - 困境 内外交困，限制时空，升级麻烦，逼入绝境<br>    -  A故事是人物外在的故事，B故事是人物内在的需求，往往是故事人物弧光所在 A明B暗 <a href="https://movie.douban.com/subject/1777612/">阳光小美女 (豆瓣) (douban.com)</a><br>    - 游戏时间，欢乐时光：气口，节奏是在变化中产生的<br>    - <a href="https://www.sohu.com/a/404209563_120067926">编剧养成记：经典剧本“节拍表”创作流程解析_故事 (sohu.com)</a><br>    - </p><p>冲突：困境 需求</p><ul><li>设置冲突的方法：设置多重阻力，设置九九八十一难，建置扎实的人物关系（人物关系自带麻烦）。</li><li>冲突可以换但不可以断。基础冲突是二元冲突，高级冲突是价值观的冲突。</li><li>冲突源于不等，越不等的人物越容易发生冲突。冲突源于反差。</li></ul><p>人物：<br>塑造人物：人设 人物关系 人物塑造</p><ul><li><p>人物小传</p><ul><li>外在</li><li>内在</li><li>状态</li><li>行动</li><li>变化</li><li>不写最后的结局，选择命运</li></ul></li><li><p>人物类型</p></li><li><p>牙刷大肠理论</p></li><li><p>身份</p><ul><li>三可：可怜 可爱 可信</li></ul></li><li><p>欲望</p><ul><li>原始的，本真的</li></ul></li><li><p>动作</p><ul><li>合理化</li></ul></li><li><p>人物关系</p><ul><li>人物与人物</li><li>人物与自己</li></ul></li><li><p>人物塑造：</p></li><li><p>方法一</p><ul><li>从规定情境触发，设计规定情境并准确地塑造规定情境中的人</li><li>情境时人物行动的依据，情境自身也在发展变化<ul><li>新龙门客栈、花样年华、黄土地、南方车站的聚会</li><li>情书</li></ul></li><li>通过情境的变化，多样来呈现人物性格的复杂多面，创造不同情境，并且写出人物在不同情境中的变化</li><li>情境：常态、非常态、极端。职业生活、私生活、个人生活。</li></ul></li><li><p>方法三:给出明确的人物需求</p></li><li><p>方法四：创造出人物弧–人物成长或改变的轨迹</p><ul><li>我不是药神 去欲望化</li></ul></li><li><p>方法五：为人物贴上个性化的标签</p><ul><li>反复强调，不断的去贴同一个标签</li></ul></li><li><p>方法六：通过行为&#x2F;动作刻画性格 </p><ul><li>确立人物和目标的关系</li><li>设计人物的个性化&#x2F;习惯性动作</li><li>通过别人</li></ul></li><li><p>方法七：利用反差&#x2F;分裂刻画人物</p><ul><li>说与做的分裂</li><li>内心动作与外部动作的分裂</li><li>习惯与此时此刻的分裂</li><li>常态与反常态形成反差</li></ul></li><li><p>方法八：利用对比手法，使用衬角</p></li><li><p>方法九：利用对白台词 </p></li><li><p>人物对白</p><ul><li>1、符合人物身份</li><li>2、展示而不是告诉，台词要用来塑造性格而不是交代性格，人物是被呈现出来的</li><li>3、语感，避免说教，呆板 文学化书面化</li><li>4、动作性 潜台词</li><li>5、能不用台词的地方就不用台词，高度影像化的电影<ul><li>对白带上某种情绪，通过动作  为人物开一扇窗</li><li>让对白蕴含丰富的内心动作</li><li>给观众留白</li></ul></li><li>6、不能脱离情境</li><li>7、语言简洁<ul><li>删除重复的语言</li><li>人物说话有层次</li><li>穿插对方情绪反应</li></ul></li><li>8、已经在画面中显示的信息不要重复<br>写好对白的两大原则：<br>1、贴着人物写，对白来自于这个人物<br>2、贴着情境写，对白来自于规定情境</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;共情&quot;&gt;&lt;a href=&quot;#共情&quot; class=&quot;headerlink&quot; title=&quot;共情&quot;&gt;&lt;/a&gt;共情&lt;/h1&gt;&lt;p&gt;目录&lt;br&gt;确立影像化思维&lt;br&gt;重点概念：场景&lt;br&gt;电影文本长什么样&lt;br&gt;故事的道德前提&lt;br&gt;用结构来讲故事&lt;br&gt;拿事儿说话&lt;br</summary>
      
    
    
    
    <category term="课程笔记" scheme="http://holmodi.fun/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="电影" scheme="http://holmodi.fun/tags/%E7%94%B5%E5%BD%B1/"/>
    
  </entry>
  
</feed>
